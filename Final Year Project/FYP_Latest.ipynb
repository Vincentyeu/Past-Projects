{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53220ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My numpy version is:  1.26.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "print(\"My numpy version is: \", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e7ce204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "797d5152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.10.1\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\yeuvi\\anaconda3\\envs\\py310\\lib\\site-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, keras-preprocessing, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43b0366c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.24\n",
      "  Downloading numpy-1.24.0-cp310-cp310-win_amd64.whl.metadata (5.6 kB)\n",
      "Downloading numpy-1.24.0-cp310-cp310-win_amd64.whl (14.8 MB)\n",
      "   ---------------------------------------- 0.0/14.8 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.9/14.8 MB 16.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.4/14.8 MB 21.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.3/14.8 MB 20.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.8/14.8 MB 21.7 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.0\n",
      "    Uninstalling numpy-1.23.0:\n",
      "      Successfully uninstalled numpy-1.23.0\n",
      "Successfully installed numpy-1.24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\yeuvi\\anaconda3\\envs\\py310\\Lib\\site-packages\\~~mpy'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd43e7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv1D, Bidirectional, LSTM, Dense, Dropout, GlobalAveragePooling1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e300a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the data column in protocol file\n",
    "# These are by any strings, they are just names of the column in dataFrame\n",
    "# There is no need to change these\n",
    "\n",
    "# column for trial name\n",
    "df_name_trial = 'trial'\n",
    "# column for key (bonafide/spoof)\n",
    "df_name_label = 'label'\n",
    "# column for the (w/ non-speech and w/o non-speech)\n",
    "df_name_trim = 'trim'\n",
    "# column for subset (progress, eval, hidden, ...)\n",
    "df_name_subset = 'subset'\n",
    "# column for score\n",
    "df_name_score  = 'score'\n",
    "# column for compression\n",
    "df_name_compr = 'compression'\n",
    "# column for data source\n",
    "df_name_source = 'source'\n",
    "# column for vocoder type\n",
    "df_name_vocoder = 'vocoder'\n",
    "# column for spoofing attack\n",
    "df_name_attack = 'attack'\n",
    "# column for speaker ID\n",
    "df_name_speaker = 'speaker'\n",
    "\n",
    "\n",
    "# value of the pooled condition\n",
    "df_pooled_tag = 'Pooled'\n",
    "\n",
    "# ====\n",
    "# For loading key and meta labels\n",
    "# ====\n",
    "# names of column to load protocol file\n",
    "# the order of column should not be changed\n",
    "df_protocol_names = [df_name_speaker,df_name_trial,\n",
    "                     df_name_compr, df_name_source, df_name_attack, df_name_label,\n",
    "                     df_name_trim, df_name_subset, df_name_vocoder, \n",
    "                     'task', 'team', 'gender-pair', 'language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46dad524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_protocol_21(protocol_file, names, sep=' ', index_col=None):\n",
    "    pd_protocol = pd.read_csv(protocol_file, sep=' ', names=names, \n",
    "                                  index_col = index_col, skipinitialspace=True)\n",
    "    return pd_protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c515fc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>compression</th>\n",
       "      <th>source</th>\n",
       "      <th>attack</th>\n",
       "      <th>label</th>\n",
       "      <th>trim</th>\n",
       "      <th>subset</th>\n",
       "      <th>vocoder</th>\n",
       "      <th>task</th>\n",
       "      <th>team</th>\n",
       "      <th>gender-pair</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DF_E_2000011</th>\n",
       "      <td>LA_0023</td>\n",
       "      <td>nocodec</td>\n",
       "      <td>asvspoof</td>\n",
       "      <td>A14</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>progress</td>\n",
       "      <td>traditional_vocoder</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF_E_2000013</th>\n",
       "      <td>TEF2</td>\n",
       "      <td>low_m4a</td>\n",
       "      <td>vcc2020</td>\n",
       "      <td>Task1-team20</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>neural_vocoder_nonautoregressive</td>\n",
       "      <td>Task1</td>\n",
       "      <td>team20</td>\n",
       "      <td>FF</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF_E_2000024</th>\n",
       "      <td>TGF1</td>\n",
       "      <td>mp3m4a</td>\n",
       "      <td>vcc2020</td>\n",
       "      <td>Task2-team12</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>traditional_vocoder</td>\n",
       "      <td>Task2</td>\n",
       "      <td>team12</td>\n",
       "      <td>FF</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF_E_2000026</th>\n",
       "      <td>LA_0043</td>\n",
       "      <td>mp3m4a</td>\n",
       "      <td>asvspoof</td>\n",
       "      <td>A09</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>traditional_vocoder</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF_E_2000027</th>\n",
       "      <td>LA_0021</td>\n",
       "      <td>mp3m4a</td>\n",
       "      <td>asvspoof</td>\n",
       "      <td>A12</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>neural_vocoder_autoregressive</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF_E_4999945</th>\n",
       "      <td>VCC2TM2</td>\n",
       "      <td>oggm4a</td>\n",
       "      <td>vcc2018</td>\n",
       "      <td>SPO-N16</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>traditional_vocoder</td>\n",
       "      <td>SPO</td>\n",
       "      <td>N16</td>\n",
       "      <td>FM</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF_E_4999962</th>\n",
       "      <td>LA_0044</td>\n",
       "      <td>oggm4a</td>\n",
       "      <td>asvspoof</td>\n",
       "      <td>A19</td>\n",
       "      <td>spoof</td>\n",
       "      <td>trim</td>\n",
       "      <td>hidden</td>\n",
       "      <td>traditional_vocoder</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF_E_4999964</th>\n",
       "      <td>LA_0042</td>\n",
       "      <td>high_ogg</td>\n",
       "      <td>asvspoof</td>\n",
       "      <td>A13</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>traditional_vocoder</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF_E_4999980</th>\n",
       "      <td>TEM1</td>\n",
       "      <td>low_m4a</td>\n",
       "      <td>vcc2020</td>\n",
       "      <td>Task1-team07</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>neural_vocoder_autoregressive</td>\n",
       "      <td>Task1</td>\n",
       "      <td>team07</td>\n",
       "      <td>FM</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF_E_4999993</th>\n",
       "      <td>TGF1</td>\n",
       "      <td>mp3m4a</td>\n",
       "      <td>vcc2020</td>\n",
       "      <td>Task2-team33</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>neural_vocoder_nonautoregressive</td>\n",
       "      <td>Task2</td>\n",
       "      <td>team33</td>\n",
       "      <td>MF</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>611829 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              speaker compression    source        attack  label    trim  \\\n",
       "trial                                                                      \n",
       "DF_E_2000011  LA_0023     nocodec  asvspoof           A14  spoof  notrim   \n",
       "DF_E_2000013     TEF2     low_m4a   vcc2020  Task1-team20  spoof  notrim   \n",
       "DF_E_2000024     TGF1      mp3m4a   vcc2020  Task2-team12  spoof  notrim   \n",
       "DF_E_2000026  LA_0043      mp3m4a  asvspoof           A09  spoof  notrim   \n",
       "DF_E_2000027  LA_0021      mp3m4a  asvspoof           A12  spoof  notrim   \n",
       "...               ...         ...       ...           ...    ...     ...   \n",
       "DF_E_4999945  VCC2TM2      oggm4a   vcc2018       SPO-N16  spoof  notrim   \n",
       "DF_E_4999962  LA_0044      oggm4a  asvspoof           A19  spoof    trim   \n",
       "DF_E_4999964  LA_0042    high_ogg  asvspoof           A13  spoof  notrim   \n",
       "DF_E_4999980     TEM1     low_m4a   vcc2020  Task1-team07  spoof  notrim   \n",
       "DF_E_4999993     TGF1      mp3m4a   vcc2020  Task2-team33  spoof  notrim   \n",
       "\n",
       "                subset                           vocoder   task    team  \\\n",
       "trial                                                                     \n",
       "DF_E_2000011  progress               traditional_vocoder      -       -   \n",
       "DF_E_2000013      eval  neural_vocoder_nonautoregressive  Task1  team20   \n",
       "DF_E_2000024      eval               traditional_vocoder  Task2  team12   \n",
       "DF_E_2000026      eval               traditional_vocoder      -       -   \n",
       "DF_E_2000027      eval     neural_vocoder_autoregressive      -       -   \n",
       "...                ...                               ...    ...     ...   \n",
       "DF_E_4999945      eval               traditional_vocoder    SPO     N16   \n",
       "DF_E_4999962    hidden               traditional_vocoder      -       -   \n",
       "DF_E_4999964      eval               traditional_vocoder      -       -   \n",
       "DF_E_4999980      eval     neural_vocoder_autoregressive  Task1  team07   \n",
       "DF_E_4999993      eval  neural_vocoder_nonautoregressive  Task2  team33   \n",
       "\n",
       "             gender-pair language  \n",
       "trial                              \n",
       "DF_E_2000011           -        -  \n",
       "DF_E_2000013          FF        E  \n",
       "DF_E_2000024          FF        G  \n",
       "DF_E_2000026           -        -  \n",
       "DF_E_2000027           -        -  \n",
       "...                  ...      ...  \n",
       "DF_E_4999945          FM        -  \n",
       "DF_E_4999962           -        -  \n",
       "DF_E_4999964           -        -  \n",
       "DF_E_4999980          FM        E  \n",
       "DF_E_4999993          MF        G  \n",
       "\n",
       "[611829 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_protocol_file = 'C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/DF-keys-full.tar/keys/DF/CM/trial_metadata.txt'\n",
    "df_protocol_pd = load_protocol_21(df_protocol_file, names = df_protocol_names, index_col = df_name_trial)\n",
    "df_protocol_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f86a112a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "bonafide     22617\n",
       "spoof       589212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_protocol_pd['label'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea793fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>compression</th>\n",
       "      <th>source</th>\n",
       "      <th>attack</th>\n",
       "      <th>label</th>\n",
       "      <th>trim</th>\n",
       "      <th>subset</th>\n",
       "      <th>vocoder</th>\n",
       "      <th>task</th>\n",
       "      <th>team</th>\n",
       "      <th>gender-pair</th>\n",
       "      <th>language</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DF_E_2000011</th>\n",
       "      <td>LA_0023</td>\n",
       "      <td>nocodec</td>\n",
       "      <td>asvspoof</td>\n",
       "      <td>A14</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>progress</td>\n",
       "      <td>traditional_vocoder</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF_E_2000013</th>\n",
       "      <td>TEF2</td>\n",
       "      <td>low_m4a</td>\n",
       "      <td>vcc2020</td>\n",
       "      <td>Task1-team20</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>neural_vocoder_nonautoregressive</td>\n",
       "      <td>Task1</td>\n",
       "      <td>team20</td>\n",
       "      <td>FF</td>\n",
       "      <td>E</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF_E_2000024</th>\n",
       "      <td>TGF1</td>\n",
       "      <td>mp3m4a</td>\n",
       "      <td>vcc2020</td>\n",
       "      <td>Task2-team12</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>traditional_vocoder</td>\n",
       "      <td>Task2</td>\n",
       "      <td>team12</td>\n",
       "      <td>FF</td>\n",
       "      <td>G</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF_E_2000026</th>\n",
       "      <td>LA_0043</td>\n",
       "      <td>mp3m4a</td>\n",
       "      <td>asvspoof</td>\n",
       "      <td>A09</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>traditional_vocoder</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF_E_2000027</th>\n",
       "      <td>LA_0021</td>\n",
       "      <td>mp3m4a</td>\n",
       "      <td>asvspoof</td>\n",
       "      <td>A12</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>neural_vocoder_autoregressive</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF_E_2749666</th>\n",
       "      <td>VCC2TM2</td>\n",
       "      <td>low_ogg</td>\n",
       "      <td>vcc2018</td>\n",
       "      <td>HUB-D05</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>traditional_vocoder</td>\n",
       "      <td>HUB</td>\n",
       "      <td>D05</td>\n",
       "      <td>MM</td>\n",
       "      <td>-</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF_E_2749668</th>\n",
       "      <td>VCC2TF2</td>\n",
       "      <td>high_ogg</td>\n",
       "      <td>vcc2018</td>\n",
       "      <td>SPO-N12</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>traditional_vocoder</td>\n",
       "      <td>SPO</td>\n",
       "      <td>N12</td>\n",
       "      <td>FF</td>\n",
       "      <td>-</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF_E_2749677</th>\n",
       "      <td>LA_0021</td>\n",
       "      <td>low_mp3</td>\n",
       "      <td>asvspoof</td>\n",
       "      <td>A15</td>\n",
       "      <td>spoof</td>\n",
       "      <td>trim</td>\n",
       "      <td>hidden</td>\n",
       "      <td>neural_vocoder_autoregressive</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF_E_2749689</th>\n",
       "      <td>TMM1</td>\n",
       "      <td>high_mp3</td>\n",
       "      <td>vcc2020</td>\n",
       "      <td>Task2-team33</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>neural_vocoder_nonautoregressive</td>\n",
       "      <td>Task2</td>\n",
       "      <td>team33</td>\n",
       "      <td>FM</td>\n",
       "      <td>M</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DF_E_2749694</th>\n",
       "      <td>TGM1</td>\n",
       "      <td>low_ogg</td>\n",
       "      <td>vcc2020</td>\n",
       "      <td>Task2-team27</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>neural_vocoder_nonautoregressive</td>\n",
       "      <td>Task2</td>\n",
       "      <td>team27</td>\n",
       "      <td>FM</td>\n",
       "      <td>G</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152955 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              speaker compression    source        attack  label    trim  \\\n",
       "trial                                                                      \n",
       "DF_E_2000011  LA_0023     nocodec  asvspoof           A14  spoof  notrim   \n",
       "DF_E_2000013     TEF2     low_m4a   vcc2020  Task1-team20  spoof  notrim   \n",
       "DF_E_2000024     TGF1      mp3m4a   vcc2020  Task2-team12  spoof  notrim   \n",
       "DF_E_2000026  LA_0043      mp3m4a  asvspoof           A09  spoof  notrim   \n",
       "DF_E_2000027  LA_0021      mp3m4a  asvspoof           A12  spoof  notrim   \n",
       "...               ...         ...       ...           ...    ...     ...   \n",
       "DF_E_2749666  VCC2TM2     low_ogg   vcc2018       HUB-D05  spoof  notrim   \n",
       "DF_E_2749668  VCC2TF2    high_ogg   vcc2018       SPO-N12  spoof  notrim   \n",
       "DF_E_2749677  LA_0021     low_mp3  asvspoof           A15  spoof    trim   \n",
       "DF_E_2749689     TMM1    high_mp3   vcc2020  Task2-team33  spoof  notrim   \n",
       "DF_E_2749694     TGM1     low_ogg   vcc2020  Task2-team27  spoof  notrim   \n",
       "\n",
       "                subset                           vocoder   task    team  \\\n",
       "trial                                                                     \n",
       "DF_E_2000011  progress               traditional_vocoder      -       -   \n",
       "DF_E_2000013      eval  neural_vocoder_nonautoregressive  Task1  team20   \n",
       "DF_E_2000024      eval               traditional_vocoder  Task2  team12   \n",
       "DF_E_2000026      eval               traditional_vocoder      -       -   \n",
       "DF_E_2000027      eval     neural_vocoder_autoregressive      -       -   \n",
       "...                ...                               ...    ...     ...   \n",
       "DF_E_2749666      eval               traditional_vocoder    HUB     D05   \n",
       "DF_E_2749668      eval               traditional_vocoder    SPO     N12   \n",
       "DF_E_2749677    hidden     neural_vocoder_autoregressive      -       -   \n",
       "DF_E_2749689      eval  neural_vocoder_nonautoregressive  Task2  team33   \n",
       "DF_E_2749694      eval  neural_vocoder_nonautoregressive  Task2  team27   \n",
       "\n",
       "             gender-pair language  \\\n",
       "trial                               \n",
       "DF_E_2000011           -        -   \n",
       "DF_E_2000013          FF        E   \n",
       "DF_E_2000024          FF        G   \n",
       "DF_E_2000026           -        -   \n",
       "DF_E_2000027           -        -   \n",
       "...                  ...      ...   \n",
       "DF_E_2749666          MM        -   \n",
       "DF_E_2749668          FF        -   \n",
       "DF_E_2749677           -        -   \n",
       "DF_E_2749689          FM        M   \n",
       "DF_E_2749694          FM        G   \n",
       "\n",
       "                                                     audio_path  label_num  \n",
       "trial                                                                       \n",
       "DF_E_2000011  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          1  \n",
       "DF_E_2000013  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          1  \n",
       "DF_E_2000024  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          1  \n",
       "DF_E_2000026  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          1  \n",
       "DF_E_2000027  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          1  \n",
       "...                                                         ...        ...  \n",
       "DF_E_2749666  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          1  \n",
       "DF_E_2749668  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          1  \n",
       "DF_E_2749677  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          1  \n",
       "DF_E_2749689  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          1  \n",
       "DF_E_2749694  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          1  \n",
       "\n",
       "[152955 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the exists audio file\n",
    "def load_protocol_21(protocol_file, names, sep=' ', index_col=None):\n",
    "    return pd.read_csv(protocol_file, sep=sep, names=names, index_col=index_col, skipinitialspace=True)\n",
    "\n",
    "# Paths\n",
    "df_protocol_file = 'C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/DF-keys-full.tar/keys/DF/CM/trial_metadata.txt'\n",
    "base_path = 'C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/'\n",
    "\n",
    "# Column names\n",
    "# df_protocol_names = ['trial', 'speaker_id', 'utt_id', 'spoof_type', 'label']\n",
    "df_name_trial = 'trial'\n",
    "\n",
    "\n",
    "# Load protocol\n",
    "df_protocol_pd = load_protocol_21(df_protocol_file, names=df_protocol_names, index_col=df_name_trial)\n",
    "\n",
    "# Add audio path\n",
    "df_protocol_pd['audio_path'] = df_protocol_pd.index.to_series().apply(lambda x: f'{base_path}{x}.flac')\n",
    "df_protocol_pd = df_protocol_pd[df_protocol_pd['audio_path'].apply(os.path.exists)]\n",
    "\n",
    "# Map labels\n",
    "label_mapping = {'bonafide': 0, 'spoof': 1}\n",
    "df_protocol_pd['label_num'] = df_protocol_pd['label'].map(label_mapping)\n",
    "\n",
    "df_protocol_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b98ad917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "bonafide      5535\n",
       "spoof       147420\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_protocol_pd['label'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f2cfba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>compression</th>\n",
       "      <th>source</th>\n",
       "      <th>attack</th>\n",
       "      <th>label</th>\n",
       "      <th>trim</th>\n",
       "      <th>subset</th>\n",
       "      <th>vocoder</th>\n",
       "      <th>task</th>\n",
       "      <th>team</th>\n",
       "      <th>gender-pair</th>\n",
       "      <th>language</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LA_0041</td>\n",
       "      <td>low_m4a</td>\n",
       "      <td>asvspoof</td>\n",
       "      <td>A17</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>traditional_vocoder</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LA_0051</td>\n",
       "      <td>high_mp3</td>\n",
       "      <td>asvspoof</td>\n",
       "      <td>-</td>\n",
       "      <td>bonafide</td>\n",
       "      <td>notrim</td>\n",
       "      <td>progress</td>\n",
       "      <td>bonafide</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VCC2TF2</td>\n",
       "      <td>nocodec</td>\n",
       "      <td>vcc2018</td>\n",
       "      <td>SPO-N03</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>unknown</td>\n",
       "      <td>SPO</td>\n",
       "      <td>N03</td>\n",
       "      <td>FF</td>\n",
       "      <td>-</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VCC2SF2</td>\n",
       "      <td>high_m4a</td>\n",
       "      <td>vcc2018</td>\n",
       "      <td>-</td>\n",
       "      <td>bonafide</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>bonafide</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VCC2TF2</td>\n",
       "      <td>low_m4a</td>\n",
       "      <td>vcc2018</td>\n",
       "      <td>HUB-N06</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>traditional_vocoder</td>\n",
       "      <td>HUB</td>\n",
       "      <td>N06</td>\n",
       "      <td>MF</td>\n",
       "      <td>-</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14530</th>\n",
       "      <td>TEF1</td>\n",
       "      <td>high_mp3</td>\n",
       "      <td>vcc2020</td>\n",
       "      <td>Task1-team27</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>neural_vocoder_nonautoregressive</td>\n",
       "      <td>Task1</td>\n",
       "      <td>team27</td>\n",
       "      <td>MF</td>\n",
       "      <td>E</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14531</th>\n",
       "      <td>LA_0016</td>\n",
       "      <td>low_ogg</td>\n",
       "      <td>asvspoof</td>\n",
       "      <td>A11</td>\n",
       "      <td>spoof</td>\n",
       "      <td>trim</td>\n",
       "      <td>hidden</td>\n",
       "      <td>traditional_vocoder</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14532</th>\n",
       "      <td>VCC2TF1</td>\n",
       "      <td>high_mp3</td>\n",
       "      <td>vcc2018</td>\n",
       "      <td>HUB-N15</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>traditional_vocoder</td>\n",
       "      <td>HUB</td>\n",
       "      <td>N15</td>\n",
       "      <td>FF</td>\n",
       "      <td>-</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14533</th>\n",
       "      <td>TEM1</td>\n",
       "      <td>mp3m4a</td>\n",
       "      <td>vcc2020</td>\n",
       "      <td>Task1-team12</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>traditional_vocoder</td>\n",
       "      <td>Task1</td>\n",
       "      <td>team12</td>\n",
       "      <td>MM</td>\n",
       "      <td>E</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14534</th>\n",
       "      <td>VCC2TM1</td>\n",
       "      <td>oggm4a</td>\n",
       "      <td>vcc2018</td>\n",
       "      <td>HUB-N05</td>\n",
       "      <td>spoof</td>\n",
       "      <td>notrim</td>\n",
       "      <td>eval</td>\n",
       "      <td>traditional_vocoder</td>\n",
       "      <td>HUB</td>\n",
       "      <td>N05</td>\n",
       "      <td>FM</td>\n",
       "      <td>-</td>\n",
       "      <td>C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14535 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       speaker compression    source        attack     label    trim  \\\n",
       "0      LA_0041     low_m4a  asvspoof           A17     spoof  notrim   \n",
       "1      LA_0051    high_mp3  asvspoof             -  bonafide  notrim   \n",
       "2      VCC2TF2     nocodec   vcc2018       SPO-N03     spoof  notrim   \n",
       "3      VCC2SF2    high_m4a   vcc2018             -  bonafide  notrim   \n",
       "4      VCC2TF2     low_m4a   vcc2018       HUB-N06     spoof  notrim   \n",
       "...        ...         ...       ...           ...       ...     ...   \n",
       "14530     TEF1    high_mp3   vcc2020  Task1-team27     spoof  notrim   \n",
       "14531  LA_0016     low_ogg  asvspoof           A11     spoof    trim   \n",
       "14532  VCC2TF1    high_mp3   vcc2018       HUB-N15     spoof  notrim   \n",
       "14533     TEM1      mp3m4a   vcc2020  Task1-team12     spoof  notrim   \n",
       "14534  VCC2TM1      oggm4a   vcc2018       HUB-N05     spoof  notrim   \n",
       "\n",
       "         subset                           vocoder   task    team gender-pair  \\\n",
       "0          eval               traditional_vocoder      -       -           -   \n",
       "1      progress                          bonafide      -       -           -   \n",
       "2          eval                           unknown    SPO     N03          FF   \n",
       "3          eval                          bonafide      -       -           -   \n",
       "4          eval               traditional_vocoder    HUB     N06          MF   \n",
       "...         ...                               ...    ...     ...         ...   \n",
       "14530      eval  neural_vocoder_nonautoregressive  Task1  team27          MF   \n",
       "14531    hidden               traditional_vocoder      -       -           -   \n",
       "14532      eval               traditional_vocoder    HUB     N15          FF   \n",
       "14533      eval               traditional_vocoder  Task1  team12          MM   \n",
       "14534      eval               traditional_vocoder    HUB     N05          FM   \n",
       "\n",
       "      language                                         audio_path  label_num  \n",
       "0            -  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          1  \n",
       "1            -  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          0  \n",
       "2            -  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          1  \n",
       "3            -  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          0  \n",
       "4            -  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          1  \n",
       "...        ...                                                ...        ...  \n",
       "14530        E  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          1  \n",
       "14531        -  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          1  \n",
       "14532        -  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          1  \n",
       "14533        E  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          1  \n",
       "14534        -  C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem...          1  \n",
       "\n",
       "[14535 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only 1k bonafide and 1k spoof\n",
    "bonafide_df = df_protocol_pd[df_protocol_pd['label'] == 'bonafide'].sample(5535, random_state=42)\n",
    "spoof_df = df_protocol_pd[df_protocol_pd['label'] == 'spoof'].sample(9000, random_state=42)\n",
    "\n",
    "df_small = pd.concat([bonafide_df, spoof_df])\n",
    "df_small = df_small.sample(frac=1).reset_index(drop=True)  # Shuffle\n",
    "\n",
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eb30e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "def feature_extraction(path):\n",
    "  '''\n",
    "  Generate different audio file features using librosa\n",
    "  inputs: list of audio files to extract from\n",
    "  path: path to .flac files\n",
    "  returns: columns of each newly created feature   inputs,\n",
    "  '''\n",
    "  # assert isinstance(inputs, list)\n",
    "  \n",
    "  # if len(inputs) == 0:\n",
    "  #   return \n",
    "  \n",
    "  # name_ = os.path.join(os.path.abspath(path)+'/'+str(files.file))\n",
    "  \n",
    "  # load audio files in, per librosa docs these come in as a floating point time series\n",
    "# X, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "  \n",
    "  # Mel-frequency cepstral coefficients\n",
    "  # https://towardsdatascience.com/learning-from-audio-the-mel-scale-mel-spectrograms-and-mel-frequency-cepstral-coefficients-f5752b6324a8\n",
    "  signal, sr = librosa.load(path, sr=16000)  # Load audio at 16kHz\n",
    "  feature_mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=15)\n",
    "  \n",
    "#   #https://librosa.org/doc/main/generated/librosa.feature.chroma_stft.html\n",
    "#   # http://labrosa.ee.columbia.edu/matlab/chroma-ansyn/\n",
    "#   stft = np.abs(librosa.stft(X))\n",
    "#   chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "  \n",
    "#   #https://librosa.org/doc/main/generated/librosa.feature.melspectrogram.html\n",
    "#   #https://docs.nvidia.com/deeplearning/dali/user-guide/docs/examples/audio_processing/spectrogram.html\n",
    "#   mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "  \n",
    "#   # https://www.ese.wustl.edu/~nehorai/paper/specom03.pdf\n",
    "#   contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "  \n",
    "#   # https://repositorio.inesctec.pt/bitstream/123456789/3897/1/P-00K-KKF.pdf\n",
    "#   # needs to be feed the harmonic elements from the time series\n",
    "#   tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
    "#   sr=sample_rate).T,axis=0)tonnetz,contrast,mel,chroma,stft\n",
    "  \n",
    "  return feature_mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7b2fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def librosa_feature_extraction(path):\n",
    "  '''\n",
    "  Generate different audio file features using librosa\n",
    "  inputs: list of audio files to extract from\n",
    "  path: path to .flac files\n",
    "  returns: columns of each newly created feature\n",
    "  '''\n",
    "  # assert isinstance(inputs, list)\n",
    "  \n",
    "  # if len(inputs) == 0:\n",
    "  #   return \n",
    "  \n",
    "  # name_ = os.path.join(os.path.abspath(path)+'/'+str(files.file))\n",
    "  \n",
    "  # load audio files in, per librosa docs these come in as a floating point time series\n",
    "  X, sample_rate = librosa.load(path, res_type='kaiser_fast')\n",
    "  \n",
    "  # Mel-frequency cepstral coefficients\n",
    "  # https://towardsdatascience.com/learning-from-audio-the-mel-scale-mel-spectrograms-and-mel-frequency-cepstral-coefficients-f5752b6324a8\n",
    "  mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "  \n",
    "  #https://librosa.org/doc/main/generated/librosa.feature.chroma_stft.html\n",
    "  # http://labrosa.ee.columbia.edu/matlab/chroma-ansyn/\n",
    "  stft = np.abs(librosa.stft(X))\n",
    "  chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "  \n",
    "  #https://librosa.org/doc/main/generated/librosa.feature.melspectrogram.html\n",
    "  #https://docs.nvidia.com/deeplearning/dali/user-guide/docs/examples/audio_processing/spectrogram.html\n",
    "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "  \n",
    "  # https://www.ese.wustl.edu/~nehorai/paper/specom03.pdf\n",
    "  contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "  \n",
    "  # https://repositorio.inesctec.pt/bitstream/123456789/3897/1/P-00K-KKF.pdf\n",
    "  # needs to be feed the harmonic elements from the time series\n",
    "  tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
    "    sr=sample_rate).T,axis=0)\n",
    "  \n",
    "  return tonnetz, contrast, mel, chroma, stft, mfccs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42a6189",
   "metadata": {},
   "source": [
    "Function of Melspectrogram feature extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87f026ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def melspectogram_feature_extraction(path):\n",
    "    try:\n",
    "        signal, sr = librosa.load(path, sr=16000)\n",
    "        \n",
    "        # Ensure audio is at least 1 second long\n",
    "        if len(signal) < sr:\n",
    "            signal = np.pad(signal, (0, sr - len(signal)))\n",
    "        else:\n",
    "            signal = signal[:sr]  # Trim to 1 second for consistency\n",
    "\n",
    "        # Extract 15 MFCC features and return mean over time\n",
    "        feature_melspec = librosa.feature.melspectrogram(y=signal, sr=sr)\n",
    "        mel = np.mean(feature_melspec.T,axis=0)\n",
    "\n",
    "        return mel  \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting melspectogram features from {path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a074345b",
   "metadata": {},
   "source": [
    "Melspectogram feature extraction (small dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5f20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 0/14535 [00:00<?, ?it/s]c:\\Users\\yeuvi\\anaconda3\\Lib\\site-packages\\paramiko\\pkey.py:82: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "c:\\Users\\yeuvi\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.Blowfish and will be removed from this module in 45.0.0.\n",
      "  \"class\": algorithms.Blowfish,\n",
      "c:\\Users\\yeuvi\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:243: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n",
      "Extracting features:   0%|          | 1/14535 [00:03<14:48:46,  3.67s/it]C:\\Users\\yeuvi\\AppData\\Local\\Temp\\ipykernel_44232\\370147107.py:3: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  signal, sr = librosa.load(path, sr=16000)\n",
      "c:\\Users\\yeuvi\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Extracting features: 100%|██████████| 14535/14535 [10:12<00:00, 23.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted feature shape: (14535, 128), Labels shape: (14535,)\n",
      "Melspectogram feature extraction of small dataset completed in 612.91 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Latest (can run) - Melspectogram feature extraction for the small dataset\n",
    "\n",
    "mel_features_small = []\n",
    "mel_labels_small = []\n",
    "\n",
    "#df_subset = df_small.sample(n=1000, random_state=42)\n",
    "\n",
    "start_time = time.time()  # Start the timer\n",
    "\n",
    "for idx, row in tqdm(df_small.iterrows(), total=len(df_small), desc=\"Extracting features\"):\n",
    "    path = row['audio_path']\n",
    "    label = row['label_num']\n",
    "    \n",
    "    feature_mel = melspectogram_feature_extraction(path)\n",
    "\n",
    "    if feature_mel is not None :  #and feature_mf.shape == (15,)\n",
    "        mel_features_small.append(feature_mel)\n",
    "        mel_labels_small.append(label)\n",
    "    else:\n",
    "        print(f\"Skipped {path} due to invalid feature shape.\")\n",
    "\n",
    "# Convert to NumPy array\n",
    "if mel_features_small:\n",
    "    X_mel = np.stack(mel_features_small)\n",
    "    y_mel = np.array(mel_labels_small)\n",
    "    print(f\"Extracted feature shape: {X_mel.shape}, Labels shape: {y_mel.shape}\")\n",
    "else:\n",
    "    print(\"No valid features extracted.\")\n",
    "\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "# Print duration\n",
    "print(f\"Melspectogram feature extraction of small dataset completed in {duration:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5b8437",
   "metadata": {},
   "source": [
    "Data Splitting (Mel & Small Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37669d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and validation sets (MFCC features - small dataset)\n",
    "X_mel_small_train, X_mel_small_val, y_mel_small_train, y_mel_small_val = train_test_split(X_mel_small, y_mel_small, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(f\"X_mel_small_train shape: {X_mel_small_train.shape}, X_mel_small_val shape: {X_mel_small_val.shape}\")\n",
    "print(f\"y_mel_small_train shape: {y_mel_small_train.shape}, y_mel_small_val shape: {y_mel_small_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc3c6a3",
   "metadata": {},
   "source": [
    "Melspectogram features extraction (Whole Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5917bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 0/152955 [00:00<?, ?it/s]C:\\Users\\yeuvi\\AppData\\Local\\Temp\\ipykernel_26604\\370147107.py:3: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  signal, sr = librosa.load(path, sr=16000)\n",
      "Extracting features: 100%|██████████| 152955/152955 [1:51:09<00:00, 22.93it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted feature shape: (152955, 128), Labels shape: (152955,)\n",
      "Melspectogram feature extraction of small dataset completed in 6670.14 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Latest (can run) - melspectogram feature extraction for the whole dataset\n",
    "\n",
    "mel_features_whole = []\n",
    "mel_labels_whole = []\n",
    "\n",
    "#df_subset = df_small.sample(n=1000, random_state=42)\n",
    "\n",
    "start_time = time.time()  # Start the timer\n",
    "\n",
    "for idx, row in tqdm(df_protocol_pd.iterrows(), total=len(df_protocol_pd), desc=\"Extracting features\"):\n",
    "    path = row['audio_path']\n",
    "    label = row['label_num']\n",
    "    \n",
    "    feature_mel_whole = melspectogram_feature_extraction(path)\n",
    "\n",
    "    if feature_mel_whole is not None :  #and feature_mf.shape == (15,)\n",
    "        mel_features_whole.append(feature_mel_whole)\n",
    "        mel_labels_whole.append(label)\n",
    "    else:\n",
    "        print(f\"Skipped {path} due to invalid feature shape.\")\n",
    "\n",
    "# Convert to NumPy array\n",
    "if mel_features_whole:\n",
    "    X_mel_whole = np.stack(mel_features_whole)\n",
    "    y_mel_whole = np.array(mel_labels_whole)\n",
    "    print(f\"Extracted feature shape: {X_mel_whole.shape}, Labels shape: {y_mel_whole.shape}\")\n",
    "else:\n",
    "    print(\"No valid features extracted.\")\n",
    "\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "# Print duration\n",
    "print(f\"Melspectogram feature extraction of whole dataset completed in {duration:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03aa94d",
   "metadata": {},
   "source": [
    "Data Splitting (Mel & Whole Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21536fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and validation sets (MFCC features - small dataset)\n",
    "X_mel_whole_train, X_mel_whole_val, y_mel_whole_train, y_mel_whole_val = train_test_split(X_mel_whole, y_mel_whole, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(f\"X_mel_whole_train shape: {X_mel_whole_train.shape}, X_mel_whole_val shape: {X_mel_whole_val.shape}\")\n",
    "print(f\"y_mel_whole_train shape: {y_mel_whole_train.shape}, y_mel_whole_val shape: {y_mel_whole_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128dd59c",
   "metadata": {},
   "source": [
    "Function of MFCC feature extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55d66a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Latest (can run)\n",
    "\n",
    "def mfcc_feature_extraction(path):\n",
    "    try:\n",
    "        signal, sr = librosa.load(path, sr=16000)\n",
    "        \n",
    "        # Ensure audio is at least 1 second long\n",
    "        if len(signal) < sr:\n",
    "            signal = np.pad(signal, (0, sr - len(signal)))\n",
    "        else:\n",
    "            signal = signal[:sr]  # Trim to 1 second for consistency\n",
    "\n",
    "        # Extract 15 MFCC features and return mean over time\n",
    "        feature_ccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=15)\n",
    "        mfccs_mean = np.mean(feature_ccs.T, axis=0)\n",
    "\n",
    "        return mfccs_mean  # Shape: (15,)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features from {path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ea84b2",
   "metadata": {},
   "source": [
    "MFCC feature extraction (Small dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851112c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 0/14535 [00:00<?, ?it/s]C:\\Users\\yeuvi\\AppData\\Local\\Temp\\ipykernel_44232\\123283099.py:5: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  signal, sr = librosa.load(path, sr=16000)\n",
      "Extracting features: 100%|██████████| 14535/14535 [08:18<00:00, 29.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted feature shape: (14535, 15), Labels shape: (14535,)\n",
      "MFCC feature extraction of small dataset completed in 498.57 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Latest (can run) - feature extraction for the small dataset\n",
    "\n",
    "mfcc_features_small = []\n",
    "mfcc_labels_small = []\n",
    "\n",
    "#df_subset = df_small.sample(n=1000, random_state=42)\n",
    "\n",
    "start_time = time.time()  # Start the timer\n",
    "\n",
    "for idx, row in tqdm(df_small.iterrows(), total=len(df_small), desc=\"Extracting features\"):\n",
    "    path = row['audio_path']\n",
    "    label = row['label_num']\n",
    "    \n",
    "    feature_mf_small = mfcc_feature_extraction(path)\n",
    "\n",
    "    if feature_mf_small is not None and feature_mf_small.shape == (15,):\n",
    "        mfcc_features_small.append(feature_mf_small)\n",
    "        mfcc_labels_small.append(label)\n",
    "    else:\n",
    "        print(f\"Skipped {path} due to invalid feature shape.\")\n",
    "\n",
    "# Convert to NumPy array\n",
    "if mfcc_features_small:\n",
    "    X_mfcc_small = np.stack(mfcc_features_small)\n",
    "    y_mfcc_small = np.array(mfcc_labels_small)\n",
    "    print(f\"Extracted feature shape: {X_mfcc_small.shape}, Labels shape: {y_mfcc_small.shape}\")\n",
    "else:\n",
    "    print(\"No valid features extracted.\")\n",
    "\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "# Print duration\n",
    "print(f\"MFCC feature extraction of small dataset completed in {duration:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf97df3",
   "metadata": {},
   "source": [
    "Dataset splitting (MFCC & Small Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a17af58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_mfcc_train shape: (11628, 15), X_mfcc_val shape: (2907, 15)\n",
      "y_mfcc_train shape: (11628,), y_mfcc_val shape: (2907,)\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation sets (MFCC features - small dataset)\n",
    "X_mfcc_small_train, X_mfcc_small_val, y_mfcc_small_train, y_mfcc_small_val = train_test_split(X_mfcc_small, y_mfcc_small, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(f\"X_mfcc_small_train shape: {X_mfcc_small_train.shape}, X_mfcc_small_val shape: {X_mfcc_small_val.shape}\")\n",
    "print(f\"y_mfcc_small_train shape: {y_mfcc_small_train.shape}, y_mfcc_small_val shape: {y_mfcc_small_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8f5a2d",
   "metadata": {},
   "source": [
    "MFCC feature extraction (Whole dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6f10ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 0/152955 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeuvi\\AppData\\Local\\Temp\\ipykernel_27072\\1917248033.py:5: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  signal, sr = librosa.load(path, sr=16000)\n",
      "c:\\Users\\yeuvi\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Extracting features: 100%|██████████| 152955/152955 [1:48:06<00:00, 23.58it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted feature shape: (152955, 15), Labels shape: (152955,)\n"
     ]
    }
   ],
   "source": [
    "#Latest (can run) - feature extraction for the whole dataset\n",
    "\n",
    "mfcc_features_whole = []\n",
    "mfcc_labels_whole = []\n",
    "\n",
    "#df_subset = df_small.sample(n=1000, random_state=42)\n",
    "\n",
    "for idx, row in tqdm(df_protocol_pd.iterrows(), total=len(df_protocol_pd), desc=\"Extracting features\"):\n",
    "    path = row['audio_path']\n",
    "    label = row['label_num']\n",
    "    \n",
    "    feature_mf_whole = mfcc_feature_extraction(path)\n",
    "\n",
    "    if feature_mf_whole is not None and feature_mf_whole.shape == (15,):\n",
    "        mfcc_features_whole.append(feature_mf)\n",
    "        mfcc_labels_whole.append(label)\n",
    "    else:\n",
    "        print(f\"Skipped {path} due to invalid feature shape.\")\n",
    "\n",
    "# Convert to NumPy array\n",
    "if features:\n",
    "    X_mfcc_whole = np.stack(mfcc_features_whole)\n",
    "    y_mfcc_whole = np.array(mfcc_labels_whole)\n",
    "    print(f\"Extracted feature shape: {X_mfcc_whole.shape}, Labels shape: {y_mfcc_whole.shape}\")\n",
    "else:\n",
    "    print(\"No valid features extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c49fcbb",
   "metadata": {},
   "source": [
    "Data Splitting (MFCC & Whole dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb21d2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X2_train shape: (122364, 128), X2_val shape: (30591, 128)\n",
      "y2_train shape: (122364,), y2_val shape: (30591,)\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation sets\n",
    "X_mfcc_whole_train, X_mfcc_whole_val, y_mfcc_whole_train, y_mfcc_whole_val = train_test_split(X_mfcc_whole, y_mfcc_whole, test_size=0.2, stratify=y2, random_state=42)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(f\"X_mfcc_whole_train shape: {X_mfcc_whole_train.shape}, X_mfcc_whole_val shape: {X_mfcc_whole_val.shape}\")\n",
    "print(f\"y_mfcc_whole_train shape: {y_mfcc_whole_train.shape}, y_mfcc_whole_val shape: {y_mfcc_whole_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ec7499",
   "metadata": {},
   "source": [
    "SUPPORT VECTOR MACHINE (SVM) training (Mel & Small Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e638488e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear', random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the SVM model (Melspectogram & small dataset)\n",
    "svm_model_mel_small = SVC(kernel='linear', random_state=42)\n",
    "svm_model_mel_small.fit(X_mel_small_train, y_mel_small_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29a86fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7650498796009632\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.63      0.67      1107\n",
      "           1       0.79      0.85      0.82      1800\n",
      "\n",
      "    accuracy                           0.77      2907\n",
      "   macro avg       0.75      0.74      0.74      2907\n",
      "weighted avg       0.76      0.77      0.76      2907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the target for the test set\n",
    "y_svm_mel_small_pred = svm_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm_mel_small = accuracy_score(y_mel_small_val, y_svm_mel_small_pred)\n",
    "classification_rep_svm_mel_small = classification_report(y_mel_small_val, y_svm_mel_small_pred)\n",
    "conf_matrix_svm_mel_small = confusion_matrix(y_mel_small_val, y_svm_mel_small_pred)\n",
    "\n",
    "# Display the evaluation results\n",
    "print(f'Accuracy of using SVM model with melspectogram features (Small Dataset): {accuracy_svm_mel_small}')\n",
    "print('Classification Report SVM (Melspectogram & Small Dataset):')\n",
    "print(classification_rep_svm_mel_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe346e7",
   "metadata": {},
   "source": [
    "SUPPORT VECTOR MACHINE (SVM) training (MFCC & Small Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c16f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear', random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the SVM model (MFCC & small dataset))\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_mfcc_small_train, y_mfcc_small_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6430234b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy SVM (MFCC): 0.8166494668042655\n",
      "Classification Report SVM (MFCC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.64      0.73      1107\n",
      "           1       0.81      0.93      0.86      1800\n",
      "\n",
      "    accuracy                           0.82      2907\n",
      "   macro avg       0.82      0.78      0.79      2907\n",
      "weighted avg       0.82      0.82      0.81      2907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the target for the test set\n",
    "y_svm_mfcc_small_pred = svm_model.predict(X_mfcc_small_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm_mfcc_small = accuracy_score(y_mfcc_val, y_svm_mfcc_small_pred)\n",
    "classification_rep_svm_mfcc_small = classification_report(y_mfcc_val, y_svm_mfcc_small_pred)\n",
    "conf_matrix_svm_mfcc_small = confusion_matrix(y_mfcc_val, y_svm_mfcc_small_pred)\n",
    "\n",
    "# Display the evaluation results\n",
    "print(f'Accuracy of SVM model with MFCC features (Small Dataset): {accuracy_svm_mfcc_small}')\n",
    "print('Classification Report SVM (MFCC & Small Dataset):')\n",
    "print(classification_rep_svm_mfcc_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebdc2bb",
   "metadata": {},
   "source": [
    "BiLSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "900e59c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeuvi\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">81,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">240,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">135,680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m200\u001b[0m)     │        \u001b[38;5;34m81,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m200\u001b[0m)     │       \u001b[38;5;34m240,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │       \u001b[38;5;34m135,680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m41,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m10,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">610,657</span> (2.33 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m610,657\u001b[0m (2.33 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">610,657</span> (2.33 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m610,657\u001b[0m (2.33 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model 1 (Testing 1)\n",
    "\n",
    "# Parameters\n",
    "target_sr = 16000\n",
    "target_len = 4 * target_sr  # 4 seconds (64000 samples)\n",
    "\n",
    "model1 = Sequential([\n",
    "    Bidirectional(LSTM(100, return_sequences=True), input_shape=(target_len, 1)), #1\n",
    "    Bidirectional(LSTM(100, return_sequences=True)), #2\n",
    "    Bidirectional(LSTM(64, return_sequences=True)), #3\n",
    "    Bidirectional(LSTM(64, return_sequences=True)), #4\n",
    "    Bidirectional(LSTM(32, return_sequences=True)), #5\n",
    "    # Bidirectional(LSTM(100, return_sequences=True)), #6\n",
    "    # Bidirectional(LSTM(100, return_sequences=True)), #7\n",
    "    # Bidirectional(LSTM(100, return_sequences=True)), #8\n",
    "    # Bidirectional(LSTM(100, return_sequences=True)), #9\n",
    "    Bidirectional(LSTM(16, return_sequences=False)), #10\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Use softmax for multi-class\n",
    "])\n",
    "\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "154de5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 55ms/step - accuracy: 0.7834 - loss: 0.5190 - val_accuracy: 0.7964 - val_loss: 0.4763\n",
      "Epoch 2/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - accuracy: 0.7997 - loss: 0.4754 - val_accuracy: 0.8025 - val_loss: 0.4731\n",
      "Epoch 3/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.8016 - loss: 0.4771 - val_accuracy: 0.8056 - val_loss: 0.4658\n",
      "Epoch 4/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.8150 - loss: 0.4576 - val_accuracy: 0.8108 - val_loss: 0.4566\n",
      "Epoch 5/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.8163 - loss: 0.4561 - val_accuracy: 0.8105 - val_loss: 0.4648\n",
      "Epoch 6/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.8112 - loss: 0.4581 - val_accuracy: 0.8173 - val_loss: 0.4468\n",
      "Epoch 7/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.8099 - loss: 0.4571 - val_accuracy: 0.8125 - val_loss: 0.4556\n",
      "Epoch 8/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.8259 - loss: 0.4371 - val_accuracy: 0.8156 - val_loss: 0.4451\n",
      "Epoch 9/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.8251 - loss: 0.4314 - val_accuracy: 0.8228 - val_loss: 0.4372\n",
      "Epoch 10/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.8173 - loss: 0.4409 - val_accuracy: 0.8242 - val_loss: 0.4351\n",
      "Epoch 11/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.8368 - loss: 0.4105 - val_accuracy: 0.8225 - val_loss: 0.4329\n",
      "Epoch 12/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.8356 - loss: 0.4063 - val_accuracy: 0.8239 - val_loss: 0.4218\n",
      "Epoch 13/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.8359 - loss: 0.4046 - val_accuracy: 0.8263 - val_loss: 0.4232\n",
      "Epoch 14/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.8417 - loss: 0.3957 - val_accuracy: 0.8338 - val_loss: 0.4220\n",
      "Epoch 15/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.8420 - loss: 0.3980 - val_accuracy: 0.8335 - val_loss: 0.4066\n",
      "Epoch 16/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.8475 - loss: 0.3835 - val_accuracy: 0.8308 - val_loss: 0.4100\n",
      "Epoch 17/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.8449 - loss: 0.3814 - val_accuracy: 0.8352 - val_loss: 0.4061\n",
      "Epoch 18/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.8557 - loss: 0.3587 - val_accuracy: 0.8383 - val_loss: 0.4058\n",
      "Epoch 19/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.8555 - loss: 0.3551 - val_accuracy: 0.8466 - val_loss: 0.3908\n",
      "Epoch 20/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.8695 - loss: 0.3367 - val_accuracy: 0.8418 - val_loss: 0.3808\n",
      "Epoch 21/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.8739 - loss: 0.3270 - val_accuracy: 0.8411 - val_loss: 0.3896\n",
      "Epoch 22/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.8768 - loss: 0.3122 - val_accuracy: 0.8428 - val_loss: 0.3874\n",
      "Epoch 23/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.8810 - loss: 0.3064 - val_accuracy: 0.8480 - val_loss: 0.3959\n",
      "Epoch 24/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.8832 - loss: 0.2945 - val_accuracy: 0.8380 - val_loss: 0.3844\n",
      "Epoch 25/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.8911 - loss: 0.2791 - val_accuracy: 0.8490 - val_loss: 0.4034\n",
      "Epoch 26/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.8954 - loss: 0.2679 - val_accuracy: 0.8510 - val_loss: 0.3849\n",
      "Epoch 27/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9093 - loss: 0.2419 - val_accuracy: 0.8559 - val_loss: 0.3883\n",
      "Epoch 28/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9104 - loss: 0.2270 - val_accuracy: 0.8500 - val_loss: 0.4134\n",
      "Epoch 29/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9137 - loss: 0.2206 - val_accuracy: 0.8517 - val_loss: 0.4334\n",
      "Epoch 30/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9213 - loss: 0.2009 - val_accuracy: 0.8483 - val_loss: 0.4238\n",
      "Epoch 31/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9276 - loss: 0.1872 - val_accuracy: 0.8528 - val_loss: 0.4425\n",
      "Epoch 32/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.9312 - loss: 0.1718 - val_accuracy: 0.8497 - val_loss: 0.4433\n",
      "Epoch 33/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9366 - loss: 0.1648 - val_accuracy: 0.8641 - val_loss: 0.4425\n",
      "Epoch 34/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9451 - loss: 0.1517 - val_accuracy: 0.8521 - val_loss: 0.4263\n",
      "Epoch 35/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9494 - loss: 0.1353 - val_accuracy: 0.8394 - val_loss: 0.4953\n"
     ]
    }
   ],
   "source": [
    "#Model 1 training_Melspectogram (Small dataset)\n",
    "\n",
    "history_mel_small = model1.fit(X_mfcc_train, y_mfcc_train, validation_data=(X_mfcc_val, y_mfcc_val), epochs=35, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a461d113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 56ms/step - accuracy: 0.7622 - loss: 0.5182 - val_accuracy: 0.8015 - val_loss: 0.4695\n",
      "Epoch 2/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.7951 - loss: 0.4849 - val_accuracy: 0.8025 - val_loss: 0.4749\n",
      "Epoch 3/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.8000 - loss: 0.4812 - val_accuracy: 0.8039 - val_loss: 0.4656\n",
      "Epoch 4/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.8038 - loss: 0.4693 - val_accuracy: 0.8074 - val_loss: 0.4574\n",
      "Epoch 5/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.8186 - loss: 0.4468 - val_accuracy: 0.8129 - val_loss: 0.4529\n",
      "Epoch 6/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.8100 - loss: 0.4526 - val_accuracy: 0.8084 - val_loss: 0.4615\n",
      "Epoch 7/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.8118 - loss: 0.4526 - val_accuracy: 0.8232 - val_loss: 0.4438\n",
      "Epoch 8/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.8276 - loss: 0.4298 - val_accuracy: 0.8191 - val_loss: 0.4392\n",
      "Epoch 9/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.8340 - loss: 0.4203 - val_accuracy: 0.8294 - val_loss: 0.4236\n",
      "Epoch 10/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.8363 - loss: 0.4168 - val_accuracy: 0.8197 - val_loss: 0.4319\n",
      "Epoch 11/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.8304 - loss: 0.4177 - val_accuracy: 0.8308 - val_loss: 0.4122\n",
      "Epoch 12/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.8353 - loss: 0.4071 - val_accuracy: 0.8170 - val_loss: 0.4286\n",
      "Epoch 13/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.8365 - loss: 0.4072 - val_accuracy: 0.8359 - val_loss: 0.4065\n",
      "Epoch 14/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.8435 - loss: 0.3915 - val_accuracy: 0.8328 - val_loss: 0.4031\n",
      "Epoch 15/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.8416 - loss: 0.3875 - val_accuracy: 0.8397 - val_loss: 0.3895\n",
      "Epoch 16/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.8470 - loss: 0.3789 - val_accuracy: 0.8407 - val_loss: 0.3964\n",
      "Epoch 17/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.8540 - loss: 0.3571 - val_accuracy: 0.8418 - val_loss: 0.3850\n",
      "Epoch 18/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.8558 - loss: 0.3466 - val_accuracy: 0.8462 - val_loss: 0.3777\n",
      "Epoch 19/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.8646 - loss: 0.3283 - val_accuracy: 0.8442 - val_loss: 0.3720\n",
      "Epoch 20/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.8712 - loss: 0.3188 - val_accuracy: 0.8507 - val_loss: 0.3685\n",
      "Epoch 21/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.8714 - loss: 0.3108 - val_accuracy: 0.8535 - val_loss: 0.3599\n",
      "Epoch 22/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.8756 - loss: 0.2947 - val_accuracy: 0.8480 - val_loss: 0.3741\n",
      "Epoch 23/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.8880 - loss: 0.2759 - val_accuracy: 0.8555 - val_loss: 0.3591\n",
      "Epoch 24/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.8911 - loss: 0.2681 - val_accuracy: 0.8510 - val_loss: 0.3702\n",
      "Epoch 25/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.9055 - loss: 0.2448 - val_accuracy: 0.8545 - val_loss: 0.3855\n",
      "Epoch 26/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.9046 - loss: 0.2338 - val_accuracy: 0.8562 - val_loss: 0.3686\n",
      "Epoch 27/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9109 - loss: 0.2155 - val_accuracy: 0.8535 - val_loss: 0.3674\n",
      "Epoch 28/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9273 - loss: 0.1955 - val_accuracy: 0.8442 - val_loss: 0.4055\n",
      "Epoch 29/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.9281 - loss: 0.1806 - val_accuracy: 0.8490 - val_loss: 0.3927\n",
      "Epoch 30/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9297 - loss: 0.1761 - val_accuracy: 0.8473 - val_loss: 0.4268\n",
      "Epoch 31/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9385 - loss: 0.1613 - val_accuracy: 0.8645 - val_loss: 0.4008\n",
      "Epoch 32/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9506 - loss: 0.1339 - val_accuracy: 0.8590 - val_loss: 0.4321\n",
      "Epoch 33/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.9515 - loss: 0.1339 - val_accuracy: 0.8524 - val_loss: 0.4729\n",
      "Epoch 34/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.9556 - loss: 0.1182 - val_accuracy: 0.8610 - val_loss: 0.4660\n",
      "Epoch 35/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9615 - loss: 0.1052 - val_accuracy: 0.8566 - val_loss: 0.4708\n"
     ]
    }
   ],
   "source": [
    "#Model 1 training_MFCC (Small dataset)\n",
    "\n",
    "history = model1.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=35, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e232bcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 72ms/step - accuracy: 0.9705 - loss: 0.0807 - val_accuracy: 0.9744 - val_loss: 0.0665\n",
      "Epoch 2/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 81ms/step - accuracy: 0.9783 - loss: 0.0574 - val_accuracy: 0.9729 - val_loss: 0.0732\n",
      "Epoch 3/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 79ms/step - accuracy: 0.9797 - loss: 0.0538 - val_accuracy: 0.9764 - val_loss: 0.0683\n",
      "Epoch 4/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 78ms/step - accuracy: 0.9807 - loss: 0.0524 - val_accuracy: 0.9767 - val_loss: 0.0690\n",
      "Epoch 5/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 88ms/step - accuracy: 0.9824 - loss: 0.0485 - val_accuracy: 0.9757 - val_loss: 0.0724\n",
      "Epoch 6/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 76ms/step - accuracy: 0.9843 - loss: 0.0455 - val_accuracy: 0.9747 - val_loss: 0.0784\n",
      "Epoch 7/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 73ms/step - accuracy: 0.9856 - loss: 0.0400 - val_accuracy: 0.9773 - val_loss: 0.0704\n",
      "Epoch 8/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 82ms/step - accuracy: 0.9871 - loss: 0.0370 - val_accuracy: 0.9793 - val_loss: 0.0672\n",
      "Epoch 9/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 81ms/step - accuracy: 0.9886 - loss: 0.0341 - val_accuracy: 0.9799 - val_loss: 0.0746\n",
      "Epoch 10/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 80ms/step - accuracy: 0.9894 - loss: 0.0309 - val_accuracy: 0.9770 - val_loss: 0.0738\n",
      "Epoch 11/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 81ms/step - accuracy: 0.9908 - loss: 0.0264 - val_accuracy: 0.9788 - val_loss: 0.0718\n",
      "Epoch 12/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 81ms/step - accuracy: 0.9916 - loss: 0.0245 - val_accuracy: 0.9805 - val_loss: 0.0749\n",
      "Epoch 13/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 80ms/step - accuracy: 0.9926 - loss: 0.0215 - val_accuracy: 0.9786 - val_loss: 0.0874\n",
      "Epoch 14/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 80ms/step - accuracy: 0.9923 - loss: 0.0231 - val_accuracy: 0.9794 - val_loss: 0.0907\n",
      "Epoch 15/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 81ms/step - accuracy: 0.9925 - loss: 0.0209 - val_accuracy: 0.9807 - val_loss: 0.0887\n"
     ]
    }
   ],
   "source": [
    "#Model 1 training_MFCC (full dataset) \n",
    "\n",
    "history1_2 = model1.fit(X2_train, y2_train, validation_data=(X2_val, y2_val), epochs=15, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a54327d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "\n",
    "model1_y2_pred_probs = model1.predict(X2_val)\n",
    "model1_y2_pred = (model1_y2_pred_probs >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f5f267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data of perdiciton checking (Make sure it is binary)\n",
    "\n",
    "model1_y2_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "698b6a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9818247196887974\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.65      0.72      1107\n",
      "           1       0.99      0.99      0.99     29484\n",
      "\n",
      "    accuracy                           0.98     30591\n",
      "   macro avg       0.90      0.82      0.86     30591\n",
      "weighted avg       0.98      0.98      0.98     30591\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model1_accuracy = accuracy_score(y2_val, model1_y2_pred)\n",
    "print(\"Accuracy:\", model1_accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y2_val, model1_y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aed59731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[  721   386]\n",
      " [  170 29314]]\n",
      "\n",
      "True Positives(TP) =  721\n",
      "\n",
      "True Negatives(TN) =  29314\n",
      "\n",
      "False Positives(FP) =  386\n",
      "\n",
      "False Negatives(FN) =  170\n"
     ]
    }
   ],
   "source": [
    "# Print the Confusion Matrix and slice it into four pieces\n",
    "\n",
    "model1_cm = confusion_matrix(y2_val, model1_y2_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', model1_cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', model1_cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', model1_cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP) = ', model1_cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN) = ', model1_cm[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c0c7d3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize confusion matrix with seaborn heatmap\n",
    "\n",
    "# bonafide = 0, spoof = 1\n",
    "\n",
    "model1_cm_matrix = pd.DataFrame(data=model1_cm, columns=['Actual Spoof:1', 'Actual Bonafide:0'], \n",
    "                                 index=['Predicted Spoof:1', 'Predicted Bonafide:0'])\n",
    "\n",
    "sns.heatmap(model1_cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13b49dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeuvi\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_48                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,792</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_49                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">183,200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_50                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">135,680</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_51                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_52                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_53                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,368</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_48                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m33,792\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_49                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m200\u001b[0m)     │       \u001b[38;5;34m183,200\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_50                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │       \u001b[38;5;34m135,680\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_51                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m41,216\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_52                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m24,832\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_53                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m10,368\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">431,265</span> (1.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m431,265\u001b[0m (1.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">431,265</span> (1.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m431,265\u001b[0m (1.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model 2 (Testin 2)\n",
    "\n",
    "# Parameters\n",
    "target_sr = 16000\n",
    "target_len = 4 * target_sr  # 4 seconds (64000 samples)\n",
    "\n",
    "model2 = Sequential([\n",
    "    Bidirectional(LSTM(64, return_sequences=True), input_shape=(target_len, 1)), #1\n",
    "    Bidirectional(LSTM(100, return_sequences=True)), #2\n",
    "    Bidirectional(LSTM(64, return_sequences=True)), #3\n",
    "    Bidirectional(LSTM(32, return_sequences=True)), #4\n",
    "    Bidirectional(LSTM(32, return_sequences=True)), #5\n",
    "    # Bidirectional(LSTM(100, return_sequences=True)), #6\n",
    "    # Bidirectional(LSTM(100, return_sequences=True)), #7\n",
    "    # Bidirectional(LSTM(100, return_sequences=True)), #8\n",
    "    # Bidirectional(LSTM(100, return_sequences=True)), #9\n",
    "    Bidirectional(LSTM(16, return_sequences=False)), #10\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Use softmax for multi-class\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a912547a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.9447 - loss: 0.2019 - val_accuracy: 0.9512 - val_loss: 0.1471\n",
      "Epoch 2/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.9613 - loss: 0.1257 - val_accuracy: 0.9501 - val_loss: 0.1586\n",
      "Epoch 3/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - accuracy: 0.9657 - loss: 0.1098 - val_accuracy: 0.9518 - val_loss: 0.1564\n",
      "Epoch 4/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - accuracy: 0.9720 - loss: 0.0870 - val_accuracy: 0.9518 - val_loss: 0.1724\n",
      "Epoch 5/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - accuracy: 0.9805 - loss: 0.0687 - val_accuracy: 0.9467 - val_loss: 0.1783\n",
      "Epoch 6/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.9777 - loss: 0.0695 - val_accuracy: 0.9439 - val_loss: 0.1750\n",
      "Epoch 7/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - accuracy: 0.9797 - loss: 0.0634 - val_accuracy: 0.9357 - val_loss: 0.2279\n",
      "Epoch 8/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.9770 - loss: 0.0640 - val_accuracy: 0.9494 - val_loss: 0.1943\n",
      "Epoch 9/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.9865 - loss: 0.0390 - val_accuracy: 0.9374 - val_loss: 0.2423\n",
      "Epoch 10/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - accuracy: 0.9825 - loss: 0.0535 - val_accuracy: 0.9398 - val_loss: 0.2431\n",
      "Epoch 11/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - accuracy: 0.9879 - loss: 0.0348 - val_accuracy: 0.9340 - val_loss: 0.2548\n",
      "Epoch 12/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - accuracy: 0.9872 - loss: 0.0376 - val_accuracy: 0.9381 - val_loss: 0.2495\n",
      "Epoch 13/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - accuracy: 0.9845 - loss: 0.0460 - val_accuracy: 0.9384 - val_loss: 0.2327\n",
      "Epoch 14/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9906 - loss: 0.0279 - val_accuracy: 0.9384 - val_loss: 0.2383\n",
      "Epoch 15/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9918 - loss: 0.0245 - val_accuracy: 0.9326 - val_loss: 0.2728\n",
      "Epoch 16/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - accuracy: 0.9934 - loss: 0.0219 - val_accuracy: 0.9343 - val_loss: 0.2403\n",
      "Epoch 17/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.9940 - loss: 0.0229 - val_accuracy: 0.9291 - val_loss: 0.2617\n",
      "Epoch 18/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - accuracy: 0.9897 - loss: 0.0283 - val_accuracy: 0.9360 - val_loss: 0.2840\n",
      "Epoch 19/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - accuracy: 0.9946 - loss: 0.0201 - val_accuracy: 0.9216 - val_loss: 0.2915\n",
      "Epoch 20/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.9873 - loss: 0.0375 - val_accuracy: 0.9384 - val_loss: 0.2852\n",
      "Epoch 21/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.9927 - loss: 0.0205 - val_accuracy: 0.9322 - val_loss: 0.2510\n",
      "Epoch 22/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.9934 - loss: 0.0205 - val_accuracy: 0.9267 - val_loss: 0.2976\n",
      "Epoch 23/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - accuracy: 0.9963 - loss: 0.0104 - val_accuracy: 0.9319 - val_loss: 0.3435\n",
      "Epoch 24/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - accuracy: 0.9926 - loss: 0.0250 - val_accuracy: 0.9284 - val_loss: 0.2839\n",
      "Epoch 25/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - accuracy: 0.9977 - loss: 0.0097 - val_accuracy: 0.9360 - val_loss: 0.3182\n",
      "Epoch 26/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9945 - loss: 0.0179 - val_accuracy: 0.9370 - val_loss: 0.2645\n",
      "Epoch 27/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - accuracy: 0.9958 - loss: 0.0146 - val_accuracy: 0.9329 - val_loss: 0.3154\n",
      "Epoch 28/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - accuracy: 0.9910 - loss: 0.0250 - val_accuracy: 0.9353 - val_loss: 0.2645\n",
      "Epoch 29/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.9957 - loss: 0.0147 - val_accuracy: 0.9288 - val_loss: 0.3491\n",
      "Epoch 30/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - accuracy: 0.9942 - loss: 0.0198 - val_accuracy: 0.9274 - val_loss: 0.2995\n",
      "Epoch 31/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9932 - loss: 0.0221 - val_accuracy: 0.9333 - val_loss: 0.2650\n",
      "Epoch 32/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - accuracy: 0.9929 - loss: 0.0234 - val_accuracy: 0.9302 - val_loss: 0.3145\n",
      "Epoch 33/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.9979 - loss: 0.0062 - val_accuracy: 0.9322 - val_loss: 0.3160\n",
      "Epoch 34/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.9910 - loss: 0.0292 - val_accuracy: 0.9357 - val_loss: 0.2641\n",
      "Epoch 35/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - accuracy: 0.9956 - loss: 0.0145 - val_accuracy: 0.9205 - val_loss: 0.2690\n"
     ]
    }
   ],
   "source": [
    "#Model 2 training \n",
    "\n",
    "history = model2.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=35, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0255a91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 63ms/step - accuracy: 0.9574 - loss: 0.1550 - val_accuracy: 0.9638 - val_loss: 0.1202\n",
      "Epoch 2/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 61ms/step - accuracy: 0.9638 - loss: 0.1212 - val_accuracy: 0.9638 - val_loss: 0.1173\n",
      "Epoch 3/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 59ms/step - accuracy: 0.9634 - loss: 0.1177 - val_accuracy: 0.9638 - val_loss: 0.1157\n",
      "Epoch 4/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 61ms/step - accuracy: 0.9650 - loss: 0.1116 - val_accuracy: 0.9682 - val_loss: 0.1103\n",
      "Epoch 5/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 60ms/step - accuracy: 0.9675 - loss: 0.1118 - val_accuracy: 0.9678 - val_loss: 0.1102\n",
      "Epoch 6/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 60ms/step - accuracy: 0.9701 - loss: 0.1063 - val_accuracy: 0.9686 - val_loss: 0.1062\n",
      "Epoch 7/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 60ms/step - accuracy: 0.9705 - loss: 0.1013 - val_accuracy: 0.9681 - val_loss: 0.1069\n",
      "Epoch 8/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 60ms/step - accuracy: 0.9718 - loss: 0.1001 - val_accuracy: 0.9709 - val_loss: 0.1000\n",
      "Epoch 9/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 60ms/step - accuracy: 0.9724 - loss: 0.0974 - val_accuracy: 0.9691 - val_loss: 0.1058\n",
      "Epoch 10/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 60ms/step - accuracy: 0.9730 - loss: 0.0961 - val_accuracy: 0.9725 - val_loss: 0.0985\n",
      "Epoch 11/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 60ms/step - accuracy: 0.9746 - loss: 0.0917 - val_accuracy: 0.9735 - val_loss: 0.0975\n",
      "Epoch 12/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 60ms/step - accuracy: 0.9754 - loss: 0.0889 - val_accuracy: 0.9720 - val_loss: 0.0967\n",
      "Epoch 13/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 59ms/step - accuracy: 0.9757 - loss: 0.0879 - val_accuracy: 0.9739 - val_loss: 0.0939\n",
      "Epoch 14/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 59ms/step - accuracy: 0.9778 - loss: 0.0816 - val_accuracy: 0.9732 - val_loss: 0.0951\n",
      "Epoch 15/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 60ms/step - accuracy: 0.9780 - loss: 0.0818 - val_accuracy: 0.9743 - val_loss: 0.0928\n"
     ]
    }
   ],
   "source": [
    "#Model 2 training (full dataset)\n",
    "\n",
    "history2_2 = model2.fit(X2_train, y2_train, validation_data=(X2_val, y2_val), epochs=15, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "977064ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions (Model 2)\n",
    "\n",
    "model2_y2_pred_probs = model2.predict(X2_val)\n",
    "model2_y2_pred = (model2_y2_pred_probs >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "41b99014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.974273479127848\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.44      0.55      1107\n",
      "           1       0.98      0.99      0.99     29484\n",
      "\n",
      "    accuracy                           0.97     30591\n",
      "   macro avg       0.86      0.72      0.77     30591\n",
      "weighted avg       0.97      0.97      0.97     30591\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model (Model 2)\n",
    "\n",
    "model2_accuracy = accuracy_score(y2_val, model2_y2_pred)\n",
    "print(\"Accuracy:\", model2_accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y2_val, model2_y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12d6c26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[  721   386]\n",
      " [  170 29314]]\n",
      "\n",
      "True Positives(TP) =  721\n",
      "\n",
      "True Negatives(TN) =  29314\n",
      "\n",
      "False Positives(FP) =  386\n",
      "\n",
      "False Negatives(FN) =  170\n"
     ]
    }
   ],
   "source": [
    "# Print the Confusion Matrix and slice it into four pieces  (Model 2)\n",
    "\n",
    "model2_cm = confusion_matrix(y2_val, model1_y2_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', model2_cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', model2_cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', model2_cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP) = ', model2_cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN) = ', model2_cm[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "54302cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize confusion matrix with seaborn heatmap (Model 2)\n",
    "\n",
    "# bonafide = 0, spoof = 1\n",
    "\n",
    "model2_cm_matrix = pd.DataFrame(data=model2_cm, columns=['Actual Spoof:1', 'Actual Bonafide:0'], \n",
    "                                 index=['Predicted Spoof:1', 'Predicted Bonafide:0'])\n",
    "\n",
    "sns.heatmap(model2_cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90d99455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeuvi\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_41                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,704</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_42                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_43                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">183,200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_44                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">240,800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_45                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">135,680</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_46                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_47                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,368</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_41                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │         \u001b[38;5;34m8,704\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_42                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_43                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m200\u001b[0m)     │       \u001b[38;5;34m183,200\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_44                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m200\u001b[0m)     │       \u001b[38;5;34m240,800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_45                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │       \u001b[38;5;34m135,680\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_46                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m41,216\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_47                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m10,368\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">688,193</span> (2.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m688,193\u001b[0m (2.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">688,193</span> (2.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m688,193\u001b[0m (2.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model 3 (Testin 3)\n",
    "\n",
    "# Parameters\n",
    "target_sr = 16000\n",
    "target_len = 4 * target_sr  # 4 seconds (64000 samples)\n",
    "\n",
    "model3 = Sequential([\n",
    "    Bidirectional(LSTM(32, return_sequences=True), input_shape=(target_len, 1)), #1\n",
    "    Bidirectional(LSTM(64, return_sequences=True)), #2\n",
    "    Bidirectional(LSTM(100, return_sequences=True)), #3\n",
    "    Bidirectional(LSTM(100, return_sequences=True)), #4\n",
    "    Bidirectional(LSTM(64, return_sequences=True)), #5\n",
    "    Bidirectional(LSTM(32, return_sequences=True)), #6\n",
    "    # Bidirectional(LSTM(100, return_sequences=True)), #7\n",
    "    # Bidirectional(LSTM(100, return_sequences=True)), #8\n",
    "    # Bidirectional(LSTM(100, return_sequences=True)), #9\n",
    "    Bidirectional(LSTM(16, return_sequences=False)), #10\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Use softmax for multi-class\n",
    "])\n",
    "\n",
    "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8842654f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 64ms/step - accuracy: 0.7566 - loss: 0.5320 - val_accuracy: 0.8015 - val_loss: 0.4773\n",
      "Epoch 2/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.8061 - loss: 0.4765 - val_accuracy: 0.7943 - val_loss: 0.4837\n",
      "Epoch 3/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step - accuracy: 0.8089 - loss: 0.4700 - val_accuracy: 0.8084 - val_loss: 0.4633\n",
      "Epoch 4/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.8140 - loss: 0.4570 - val_accuracy: 0.8132 - val_loss: 0.4523\n",
      "Epoch 5/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.8135 - loss: 0.4568 - val_accuracy: 0.8201 - val_loss: 0.4464\n",
      "Epoch 6/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.8193 - loss: 0.4453 - val_accuracy: 0.8163 - val_loss: 0.4489\n",
      "Epoch 7/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.8172 - loss: 0.4479 - val_accuracy: 0.8187 - val_loss: 0.4441\n",
      "Epoch 8/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.8301 - loss: 0.4280 - val_accuracy: 0.8215 - val_loss: 0.4372\n",
      "Epoch 9/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.8253 - loss: 0.4367 - val_accuracy: 0.8008 - val_loss: 0.4777\n",
      "Epoch 10/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.8175 - loss: 0.4519 - val_accuracy: 0.8170 - val_loss: 0.4469\n",
      "Epoch 11/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.8228 - loss: 0.4347 - val_accuracy: 0.8208 - val_loss: 0.4318\n",
      "Epoch 12/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.8227 - loss: 0.4340 - val_accuracy: 0.8235 - val_loss: 0.4307\n",
      "Epoch 13/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.8178 - loss: 0.4400 - val_accuracy: 0.8187 - val_loss: 0.4386\n",
      "Epoch 14/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.8268 - loss: 0.4279 - val_accuracy: 0.8263 - val_loss: 0.4315\n",
      "Epoch 15/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.8238 - loss: 0.4267 - val_accuracy: 0.8239 - val_loss: 0.4290\n",
      "Epoch 16/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.8355 - loss: 0.4102 - val_accuracy: 0.8228 - val_loss: 0.4299\n",
      "Epoch 17/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.8340 - loss: 0.4064 - val_accuracy: 0.8321 - val_loss: 0.4149\n",
      "Epoch 18/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.8294 - loss: 0.4173 - val_accuracy: 0.8332 - val_loss: 0.4154\n",
      "Epoch 19/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.8351 - loss: 0.4043 - val_accuracy: 0.8304 - val_loss: 0.4144\n",
      "Epoch 20/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.8316 - loss: 0.4089 - val_accuracy: 0.8129 - val_loss: 0.4339\n",
      "Epoch 21/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.8432 - loss: 0.3927 - val_accuracy: 0.8256 - val_loss: 0.4179\n",
      "Epoch 22/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.8392 - loss: 0.4037 - val_accuracy: 0.8294 - val_loss: 0.4140\n",
      "Epoch 23/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.8464 - loss: 0.3927 - val_accuracy: 0.8328 - val_loss: 0.4018\n",
      "Epoch 24/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.8426 - loss: 0.3903 - val_accuracy: 0.8177 - val_loss: 0.4257\n",
      "Epoch 25/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.8429 - loss: 0.3819 - val_accuracy: 0.8263 - val_loss: 0.4059\n",
      "Epoch 26/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.8524 - loss: 0.3741 - val_accuracy: 0.8304 - val_loss: 0.4082\n",
      "Epoch 27/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.8447 - loss: 0.3832 - val_accuracy: 0.8338 - val_loss: 0.3979\n",
      "Epoch 28/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.8485 - loss: 0.3707 - val_accuracy: 0.8366 - val_loss: 0.4016\n",
      "Epoch 29/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.8485 - loss: 0.3684 - val_accuracy: 0.8356 - val_loss: 0.4045\n",
      "Epoch 30/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.8556 - loss: 0.3596 - val_accuracy: 0.8394 - val_loss: 0.3940\n",
      "Epoch 31/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.8590 - loss: 0.3450 - val_accuracy: 0.8400 - val_loss: 0.3883\n",
      "Epoch 32/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.8577 - loss: 0.3511 - val_accuracy: 0.8414 - val_loss: 0.3926\n",
      "Epoch 33/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.8518 - loss: 0.3570 - val_accuracy: 0.8318 - val_loss: 0.4074\n",
      "Epoch 34/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.8674 - loss: 0.3313 - val_accuracy: 0.8421 - val_loss: 0.3862\n",
      "Epoch 35/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.8579 - loss: 0.3393 - val_accuracy: 0.8424 - val_loss: 0.3876\n"
     ]
    }
   ],
   "source": [
    "#Model 3 training \n",
    "\n",
    "history3 = model3.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=35, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c719793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 83ms/step - accuracy: 0.9660 - loss: 0.1036 - val_accuracy: 0.9674 - val_loss: 0.0968\n",
      "Epoch 2/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 80ms/step - accuracy: 0.9678 - loss: 0.0958 - val_accuracy: 0.9686 - val_loss: 0.0987\n",
      "Epoch 3/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 81ms/step - accuracy: 0.9701 - loss: 0.0927 - val_accuracy: 0.9697 - val_loss: 0.0933\n",
      "Epoch 4/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 81ms/step - accuracy: 0.9699 - loss: 0.0957 - val_accuracy: 0.9680 - val_loss: 0.0960\n",
      "Epoch 5/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 83ms/step - accuracy: 0.9713 - loss: 0.0895 - val_accuracy: 0.9698 - val_loss: 0.0959\n",
      "Epoch 6/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 83ms/step - accuracy: 0.9726 - loss: 0.0867 - val_accuracy: 0.9691 - val_loss: 0.0998\n",
      "Epoch 7/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 85ms/step - accuracy: 0.9731 - loss: 0.0867 - val_accuracy: 0.9709 - val_loss: 0.0941\n",
      "Epoch 8/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 82ms/step - accuracy: 0.9755 - loss: 0.0820 - val_accuracy: 0.9729 - val_loss: 0.0901\n",
      "Epoch 9/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 84ms/step - accuracy: 0.9764 - loss: 0.0781 - val_accuracy: 0.9743 - val_loss: 0.0894\n",
      "Epoch 10/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 85ms/step - accuracy: 0.9767 - loss: 0.0760 - val_accuracy: 0.9731 - val_loss: 0.0899\n",
      "Epoch 11/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 83ms/step - accuracy: 0.9778 - loss: 0.0734 - val_accuracy: 0.9755 - val_loss: 0.0868\n",
      "Epoch 12/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 82ms/step - accuracy: 0.9790 - loss: 0.0701 - val_accuracy: 0.9748 - val_loss: 0.0877\n",
      "Epoch 13/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 84ms/step - accuracy: 0.9795 - loss: 0.0659 - val_accuracy: 0.9754 - val_loss: 0.0867\n",
      "Epoch 14/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 82ms/step - accuracy: 0.9818 - loss: 0.0612 - val_accuracy: 0.9745 - val_loss: 0.0891\n",
      "Epoch 15/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 85ms/step - accuracy: 0.9810 - loss: 0.0631 - val_accuracy: 0.9732 - val_loss: 0.0925\n"
     ]
    }
   ],
   "source": [
    "#Model 3 training (full dataset) \n",
    "\n",
    "history3_2 = model3.fit(X2_train, y2_train, validation_data=(X2_val, y2_val), epochs=15, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acc1cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions (Model 3)\n",
    "\n",
    "model3_y2_pred_probs = model3.predict(X2_val)\n",
    "model3_y2_pred = (model3_y2_pred_probs >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05c221d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9731947304762839\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.52      0.58      1107\n",
      "           1       0.98      0.99      0.99     29484\n",
      "\n",
      "    accuracy                           0.97     30591\n",
      "   macro avg       0.82      0.75      0.78     30591\n",
      "weighted avg       0.97      0.97      0.97     30591\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model (Model 3)\n",
    "\n",
    "model3_accuracy = accuracy_score(y2_val, model3_y2_pred)\n",
    "print(\"Accuracy:\", model3_accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y2_val, model3_y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e87bff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[  573   534]\n",
      " [  286 29198]]\n",
      "\n",
      "True Positives(TP) =  573\n",
      "\n",
      "True Negatives(TN) =  29198\n",
      "\n",
      "False Positives(FP) =  534\n",
      "\n",
      "False Negatives(FN) =  286\n"
     ]
    }
   ],
   "source": [
    "# Print the Confusion Matrix and slice it into four pieces  (Model 3)\n",
    "\n",
    "model3_cm = confusion_matrix(y2_val, model3_y2_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', model3_cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', model3_cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', model3_cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP) = ', model3_cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN) = ', model3_cm[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "45f1f6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize confusion matrix with seaborn heatmap (Model 3)\n",
    "\n",
    "# bonafide = 0, spoof = 1\n",
    "\n",
    "model3_cm_matrix = pd.DataFrame(data=model3_cm, columns=['Actual Spoof:1', 'Actual Bonafide:0'], \n",
    "                                 index=['Predicted Spoof:1', 'Predicted Bonafide:0'])\n",
    "\n",
    "sns.heatmap(model3_cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43202b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_10                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">81,600</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_11                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">240,800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_12                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">240,800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_13                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">240,800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_14                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">240,800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_15                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">240,800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_16                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">240,800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_17                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">240,800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_18                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">240,800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_19                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">27,776</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_10                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m200\u001b[0m)     │        \u001b[38;5;34m81,600\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_11                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m200\u001b[0m)     │       \u001b[38;5;34m240,800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_12                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m200\u001b[0m)     │       \u001b[38;5;34m240,800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_13                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m200\u001b[0m)     │       \u001b[38;5;34m240,800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_14                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m200\u001b[0m)     │       \u001b[38;5;34m240,800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_15                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m200\u001b[0m)     │       \u001b[38;5;34m240,800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_16                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m200\u001b[0m)     │       \u001b[38;5;34m240,800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_17                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m200\u001b[0m)     │       \u001b[38;5;34m240,800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_18                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64000\u001b[0m, \u001b[38;5;34m200\u001b[0m)     │       \u001b[38;5;34m240,800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_19                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m27,776\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,037,953</span> (7.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,037,953\u001b[0m (7.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,037,953</span> (7.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,037,953\u001b[0m (7.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model 4 (Testin 4)\n",
    "\n",
    "# Parameters\n",
    "target_sr = 16000\n",
    "target_len = 4 * target_sr  # 4 seconds (64000 samples)\n",
    "\n",
    "model4 = Sequential([\n",
    "    Bidirectional(LSTM(100, return_sequences=True), input_shape=(target_len, 1)), #1\n",
    "    Bidirectional(LSTM(100, return_sequences=True)), #2\n",
    "    Bidirectional(LSTM(100, return_sequences=True)), #3\n",
    "    Bidirectional(LSTM(100, return_sequences=True)), #4\n",
    "    Bidirectional(LSTM(100, return_sequences=True)), #5\n",
    "    Bidirectional(LSTM(100, return_sequences=True)), #6\n",
    "    Bidirectional(LSTM(100, return_sequences=True)), #7\n",
    "    Bidirectional(LSTM(100, return_sequences=True)), #8\n",
    "    Bidirectional(LSTM(100, return_sequences=True)), #9\n",
    "    Bidirectional(LSTM(16, return_sequences=False)), #10\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Use softmax for multi-class\n",
    "])\n",
    "\n",
    "model4.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d87abaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 192ms/step - accuracy: 0.7842 - loss: 0.5209 - val_accuracy: 0.7891 - val_loss: 0.5109\n",
      "Epoch 2/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 190ms/step - accuracy: 0.8028 - loss: 0.4852 - val_accuracy: 0.7943 - val_loss: 0.4843\n",
      "Epoch 3/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 196ms/step - accuracy: 0.8008 - loss: 0.4754 - val_accuracy: 0.7998 - val_loss: 0.4844\n",
      "Epoch 4/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 189ms/step - accuracy: 0.8012 - loss: 0.4724 - val_accuracy: 0.8063 - val_loss: 0.4770\n",
      "Epoch 5/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 183ms/step - accuracy: 0.8081 - loss: 0.4696 - val_accuracy: 0.8019 - val_loss: 0.4718\n",
      "Epoch 6/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 178ms/step - accuracy: 0.8034 - loss: 0.4622 - val_accuracy: 0.8149 - val_loss: 0.4674\n",
      "Epoch 7/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 179ms/step - accuracy: 0.8204 - loss: 0.4443 - val_accuracy: 0.8232 - val_loss: 0.4551\n",
      "Epoch 8/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 198ms/step - accuracy: 0.8084 - loss: 0.4672 - val_accuracy: 0.8084 - val_loss: 0.4807\n",
      "Epoch 9/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 194ms/step - accuracy: 0.8086 - loss: 0.4612 - val_accuracy: 0.8208 - val_loss: 0.4519\n",
      "Epoch 10/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 198ms/step - accuracy: 0.8161 - loss: 0.4457 - val_accuracy: 0.8208 - val_loss: 0.4463\n",
      "Epoch 11/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 193ms/step - accuracy: 0.8273 - loss: 0.4373 - val_accuracy: 0.8242 - val_loss: 0.4434\n",
      "Epoch 12/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 196ms/step - accuracy: 0.8157 - loss: 0.4475 - val_accuracy: 0.8132 - val_loss: 0.4423\n",
      "Epoch 13/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 224ms/step - accuracy: 0.8226 - loss: 0.4334 - val_accuracy: 0.8249 - val_loss: 0.4432\n",
      "Epoch 14/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 190ms/step - accuracy: 0.8190 - loss: 0.4349 - val_accuracy: 0.8290 - val_loss: 0.4333\n",
      "Epoch 15/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 193ms/step - accuracy: 0.8249 - loss: 0.4265 - val_accuracy: 0.8304 - val_loss: 0.4345\n",
      "Epoch 16/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 196ms/step - accuracy: 0.8305 - loss: 0.4202 - val_accuracy: 0.8332 - val_loss: 0.4208\n",
      "Epoch 17/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 190ms/step - accuracy: 0.8344 - loss: 0.4198 - val_accuracy: 0.8297 - val_loss: 0.4246\n",
      "Epoch 18/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 186ms/step - accuracy: 0.8292 - loss: 0.4180 - val_accuracy: 0.8280 - val_loss: 0.4379\n",
      "Epoch 19/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 187ms/step - accuracy: 0.8351 - loss: 0.4112 - val_accuracy: 0.8363 - val_loss: 0.4288\n",
      "Epoch 20/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 186ms/step - accuracy: 0.8375 - loss: 0.4004 - val_accuracy: 0.8376 - val_loss: 0.4058\n",
      "Epoch 21/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 182ms/step - accuracy: 0.8380 - loss: 0.4034 - val_accuracy: 0.8383 - val_loss: 0.4076\n",
      "Epoch 22/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 184ms/step - accuracy: 0.8441 - loss: 0.3832 - val_accuracy: 0.8428 - val_loss: 0.3935\n",
      "Epoch 23/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 183ms/step - accuracy: 0.8461 - loss: 0.3820 - val_accuracy: 0.8435 - val_loss: 0.3924\n",
      "Epoch 24/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 186ms/step - accuracy: 0.8512 - loss: 0.3709 - val_accuracy: 0.8531 - val_loss: 0.3807\n",
      "Epoch 25/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 184ms/step - accuracy: 0.8490 - loss: 0.3718 - val_accuracy: 0.8507 - val_loss: 0.3797\n",
      "Epoch 26/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 184ms/step - accuracy: 0.8576 - loss: 0.3508 - val_accuracy: 0.8435 - val_loss: 0.3968\n",
      "Epoch 27/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 182ms/step - accuracy: 0.8567 - loss: 0.3513 - val_accuracy: 0.8538 - val_loss: 0.3932\n",
      "Epoch 28/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 181ms/step - accuracy: 0.8633 - loss: 0.3399 - val_accuracy: 0.8486 - val_loss: 0.4006\n",
      "Epoch 29/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 182ms/step - accuracy: 0.8692 - loss: 0.3255 - val_accuracy: 0.8545 - val_loss: 0.3730\n",
      "Epoch 30/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 182ms/step - accuracy: 0.8680 - loss: 0.3238 - val_accuracy: 0.8593 - val_loss: 0.3695\n",
      "Epoch 31/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 182ms/step - accuracy: 0.8790 - loss: 0.3052 - val_accuracy: 0.8566 - val_loss: 0.3709\n",
      "Epoch 32/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 183ms/step - accuracy: 0.8789 - loss: 0.2941 - val_accuracy: 0.8600 - val_loss: 0.3710\n",
      "Epoch 33/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 185ms/step - accuracy: 0.8848 - loss: 0.2868 - val_accuracy: 0.8524 - val_loss: 0.4011\n",
      "Epoch 34/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 184ms/step - accuracy: 0.8924 - loss: 0.2790 - val_accuracy: 0.8652 - val_loss: 0.3535\n",
      "Epoch 35/35\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 179ms/step - accuracy: 0.8981 - loss: 0.2567 - val_accuracy: 0.8621 - val_loss: 0.3558\n"
     ]
    }
   ],
   "source": [
    "#Model 4 training (small dataset)\n",
    "\n",
    "history4 = model4.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=35, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1ac1138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 362ms/step - accuracy: 0.9652 - loss: 0.0997 - val_accuracy: 0.9700 - val_loss: 0.0860\n",
      "Epoch 2/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 376ms/step - accuracy: 0.9709 - loss: 0.0823 - val_accuracy: 0.9702 - val_loss: 0.0858\n",
      "Epoch 3/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 375ms/step - accuracy: 0.9730 - loss: 0.0782 - val_accuracy: 0.9724 - val_loss: 0.0851\n",
      "Epoch 4/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 361ms/step - accuracy: 0.9754 - loss: 0.0738 - val_accuracy: 0.9720 - val_loss: 0.0873\n",
      "Epoch 5/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 362ms/step - accuracy: 0.9755 - loss: 0.0743 - val_accuracy: 0.9728 - val_loss: 0.0883\n",
      "Epoch 6/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 367ms/step - accuracy: 0.9754 - loss: 0.0718 - val_accuracy: 0.9750 - val_loss: 0.0840\n",
      "Epoch 7/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 360ms/step - accuracy: 0.9769 - loss: 0.0698 - val_accuracy: 0.9753 - val_loss: 0.0815\n",
      "Epoch 8/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 360ms/step - accuracy: 0.9785 - loss: 0.0655 - val_accuracy: 0.9745 - val_loss: 0.0802\n",
      "Epoch 9/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 360ms/step - accuracy: 0.9790 - loss: 0.0613 - val_accuracy: 0.9755 - val_loss: 0.0821\n",
      "Epoch 10/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 361ms/step - accuracy: 0.9796 - loss: 0.0608 - val_accuracy: 0.9748 - val_loss: 0.0854\n",
      "Epoch 11/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 356ms/step - accuracy: 0.9803 - loss: 0.0591 - val_accuracy: 0.9719 - val_loss: 0.0884\n",
      "Epoch 12/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 356ms/step - accuracy: 0.9792 - loss: 0.0599 - val_accuracy: 0.9766 - val_loss: 0.0898\n",
      "Epoch 13/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 357ms/step - accuracy: 0.9838 - loss: 0.0487 - val_accuracy: 0.9751 - val_loss: 0.0835\n",
      "Epoch 14/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 358ms/step - accuracy: 0.9840 - loss: 0.0474 - val_accuracy: 0.9730 - val_loss: 0.0892\n",
      "Epoch 15/15\n",
      "\u001b[1m956/956\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 357ms/step - accuracy: 0.9840 - loss: 0.0460 - val_accuracy: 0.9775 - val_loss: 0.0854\n"
     ]
    }
   ],
   "source": [
    "#Model 4 training (full dataset) \n",
    "\n",
    "history4_2 = model4.fit(X2_train, y2_train, validation_data=(X2_val, y2_val), epochs=15, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb7b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions (Model 4)\n",
    "\n",
    "model4_y2_pred_probs = model4.predict(X2_val)\n",
    "model4_y2_pred = (model4_y2_pred_probs >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3881104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model (Model 4)\n",
    "\n",
    "model3_accuracy = accuracy_score(y2_val, model4_y2_pred)\n",
    "print(\"Accuracy:\", model3_accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y2_val, model4_y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65266f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Confusion Matrix and slice it into four pieces  (Model 3)\n",
    "\n",
    "model4_cm = confusion_matrix(y2_val, model4_y2_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', model4_cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', model4_cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', model4_cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP) = ', model4_cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN) = ', model4_cm[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c90c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize confusion matrix with seaborn heatmap (Model 3)\n",
    "\n",
    "# bonafide = 0, spoof = 1\n",
    "\n",
    "model4_cm_matrix = pd.DataFrame(data=model4_cm, columns=['Actual Spoof:1', 'Actual Bonafide:0'], \n",
    "                                 index=['Predicted Spoof:1', 'Predicted Bonafide:0'])\n",
    "\n",
    "sns.heatmap(model4_cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47890064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeuvi\\anaconda3\\Lib\\site-packages\\paramiko\\pkey.py:82: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "c:\\Users\\yeuvi\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.Blowfish and will be removed from this module in 45.0.0.\n",
      "  \"class\": algorithms.Blowfish,\n",
      "c:\\Users\\yeuvi\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:243: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n",
      "Extracting features:   0%|          | 1/1000 [00:03<57:00,  3.42s/it]C:\\Users\\yeuvi\\AppData\\Local\\Temp\\ipykernel_7724\\3737368629.py:22: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  signal, sr = librosa.load(path, sr=16000)  # Load audio at 16kHz\n",
      "c:\\Users\\yeuvi\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Extracting features: 100%|██████████| 1000/1000 [00:39<00:00, 25.17it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (1000, 15) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Convert to NumPy array\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(features)\n\u001b[0;32m     26\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(labels)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted feature shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Labels shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (1000, 15) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "df_subset = df_small.sample(n=1000, random_state=42)\n",
    "\n",
    "for idx, row in tqdm(df_subset.iterrows(), total=len(df_subset), desc=\"Extracting features\"):\n",
    "    path = row['audio_path']\n",
    "    label = row['label_num']\n",
    "    \n",
    "    try:\n",
    "        feature_mf = feature_extraction(path)\n",
    "        #combined = np.hstack([tonnetz, contrast, mel, chroma, mfccs])  # Concatenate features\n",
    "        #features.append(combined)\n",
    "        features.append(feature_mf)  # Append MFCCs only for simplicity\n",
    "        labels.append(label)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {path}: {e}\")\n",
    "\n",
    "# Convert to NumPy array\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "print(f\"Extracted feature shape: {X.shape}, Labels shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d8782cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\yeuvi\\AppData\\Local\\Temp\\ipykernel_7724\\3737368629.py:22: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  signal, sr = librosa.load(path, sr=16000)  # Load audio at 16kHz\n",
      "Extracting features:   0%|          | 3/1000 [00:00<00:50, 19.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2077122.flac: (15, 123)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2244303.flac: (15, 88)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2420540.flac: (15, 103)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   2%|▏         | 15/1000 [00:00<00:25, 38.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2011647.flac: (15, 93)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2653449.flac: (15, 113)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2637622.flac: (15, 195)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2198644.flac: (15, 87)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2474164.flac: (15, 73)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2095083.flac: (15, 57)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2098278.flac: (15, 83)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2326222.flac: (15, 111)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2408465.flac: (15, 107)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2438187.flac: (15, 49)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2531576.flac: (15, 95)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2299726.flac: (15, 125)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   3%|▎         | 26/1000 [00:00<00:23, 40.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2380994.flac: (15, 57)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2329561.flac: (15, 97)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2576214.flac: (15, 77)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2377212.flac: (15, 74)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2461512.flac: (15, 140)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2652317.flac: (15, 121)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2202174.flac: (15, 61)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2173630.flac: (15, 97)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2493943.flac: (15, 71)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2652892.flac: (15, 47)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2006410.flac: (15, 49)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   3%|▎         | 31/1000 [00:00<00:31, 30.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2494452.flac: (15, 86)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2447927.flac: (15, 80)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2055447.flac: (15, 93)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2498238.flac: (15, 109)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2710023.flac: (15, 61)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2715525.flac: (15, 45)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2654114.flac: (15, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   4%|▎         | 35/1000 [00:01<00:32, 29.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2196400.flac: (15, 217)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2115839.flac: (15, 127)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2526298.flac: (15, 41)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2044364.flac: (15, 77)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   4%|▍         | 45/1000 [00:01<00:31, 30.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2000410.flac: (15, 87)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2389295.flac: (15, 103)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2533522.flac: (15, 111)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2241969.flac: (15, 118)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2222329.flac: (15, 135)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2393375.flac: (15, 123)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2304337.flac: (15, 110)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2482109.flac: (15, 95)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2103381.flac: (15, 46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   5%|▍         | 49/1000 [00:01<00:32, 29.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2287323.flac: (15, 131)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2435861.flac: (15, 107)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2295273.flac: (15, 163)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2490394.flac: (15, 173)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2571952.flac: (15, 105)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   6%|▌         | 55/1000 [00:01<00:37, 24.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2364656.flac: (15, 57)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2122772.flac: (15, 69)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2546627.flac: (15, 111)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2367499.flac: (15, 107)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2735752.flac: (15, 44)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2574714.flac: (15, 73)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2352473.flac: (15, 46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   6%|▋         | 64/1000 [00:02<00:32, 29.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2321541.flac: (15, 43)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2329607.flac: (15, 88)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2347847.flac: (15, 49)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2571063.flac: (15, 113)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2099958.flac: (15, 123)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2651863.flac: (15, 140)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2684609.flac: (15, 55)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2568153.flac: (15, 65)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2278830.flac: (15, 125)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   7%|▋         | 74/1000 [00:02<00:28, 32.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2410174.flac: (15, 57)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2660786.flac: (15, 56)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2521749.flac: (15, 215)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2282103.flac: (15, 31)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2397200.flac: (15, 83)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2398003.flac: (15, 111)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2577971.flac: (15, 72)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2436901.flac: (15, 133)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2110085.flac: (15, 77)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   8%|▊         | 85/1000 [00:02<00:22, 40.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2115808.flac: (15, 125)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2177759.flac: (15, 69)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2214013.flac: (15, 95)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2642452.flac: (15, 74)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2612301.flac: (15, 127)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2347942.flac: (15, 134)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2222086.flac: (15, 199)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2483170.flac: (15, 86)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2570486.flac: (15, 103)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2540422.flac: (15, 101)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   9%|▉         | 90/1000 [00:02<00:31, 29.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2539850.flac: (15, 109)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2350864.flac: (15, 112)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2123969.flac: (15, 95)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2357981.flac: (15, 69)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2505861.flac: (15, 167)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   9%|▉         | 94/1000 [00:03<00:32, 28.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2567290.flac: (15, 113)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2511583.flac: (15, 91)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2654529.flac: (15, 112)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2440335.flac: (15, 109)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2357062.flac: (15, 159)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2217762.flac: (15, 93)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2149531.flac: (15, 79)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  10%|█         | 104/1000 [00:03<00:30, 29.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2179437.flac: (15, 111)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2600852.flac: (15, 90)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2486180.flac: (15, 133)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2294144.flac: (15, 207)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2485112.flac: (15, 91)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2528829.flac: (15, 75)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2117133.flac: (15, 133)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2240841.flac: (15, 139)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2480368.flac: (15, 71)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  11%|█         | 109/1000 [00:03<00:29, 30.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2585969.flac: (15, 129)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2613700.flac: (15, 143)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2519081.flac: (15, 105)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  12%|█▏        | 116/1000 [00:03<00:33, 26.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2020747.flac: (15, 225)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2721115.flac: (15, 132)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2435290.flac: (15, 123)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2221545.flac: (15, 135)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2084567.flac: (15, 131)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2561492.flac: (15, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  12%|█▏        | 119/1000 [00:03<00:36, 24.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2085594.flac: (15, 130)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2145877.flac: (15, 118)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2259075.flac: (15, 93)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2748083.flac: (15, 137)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2195399.flac: (15, 92)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2168825.flac: (15, 57)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  13%|█▎        | 128/1000 [00:04<00:32, 26.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2201087.flac: (15, 137)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2745872.flac: (15, 87)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2150064.flac: (15, 101)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2137821.flac: (15, 69)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2588709.flac: (15, 127)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2675650.flac: (15, 76)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2525240.flac: (15, 93)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2399018.flac: (15, 91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  13%|█▎        | 132/1000 [00:04<00:32, 26.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2167262.flac: (15, 137)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2455958.flac: (15, 113)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2002307.flac: (15, 143)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  14%|█▎        | 135/1000 [00:04<00:41, 21.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2445633.flac: (15, 73)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2061945.flac: (15, 177)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2625270.flac: (15, 91)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2689267.flac: (15, 81)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  14%|█▍        | 141/1000 [00:04<00:37, 22.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2488198.flac: (15, 103)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2587748.flac: (15, 199)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2481388.flac: (15, 115)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2257303.flac: (15, 241)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2745903.flac: (15, 109)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2406112.flac: (15, 81)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2303725.flac: (15, 109)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2426937.flac: (15, 75)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2006530.flac: (15, 127)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  15%|█▌        | 153/1000 [00:05<00:28, 30.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2078065.flac: (15, 169)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2140317.flac: (15, 123)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2158159.flac: (15, 133)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2318831.flac: (15, 118)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2079039.flac: (15, 91)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2083919.flac: (15, 94)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2175225.flac: (15, 145)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  16%|█▌        | 157/1000 [00:05<00:29, 28.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2539556.flac: (15, 94)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2357303.flac: (15, 39)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2332822.flac: (15, 56)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2007297.flac: (15, 82)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2328985.flac: (15, 132)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2377367.flac: (15, 79)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2071913.flac: (15, 143)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2133810.flac: (15, 62)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  17%|█▋        | 166/1000 [00:05<00:29, 28.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2578948.flac: (15, 81)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2010910.flac: (15, 42)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2578319.flac: (15, 111)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2631228.flac: (15, 47)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2667091.flac: (15, 151)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  17%|█▋        | 169/1000 [00:05<00:35, 23.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2032998.flac: (15, 87)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2439486.flac: (15, 91)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2556565.flac: (15, 114)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2697892.flac: (15, 156)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2326487.flac: (15, 48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  18%|█▊        | 180/1000 [00:06<00:25, 31.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2097764.flac: (15, 91)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2148157.flac: (15, 137)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2522162.flac: (15, 70)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2101927.flac: (15, 48)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2675471.flac: (15, 27)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2088025.flac: (15, 105)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2387039.flac: (15, 83)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2536421.flac: (15, 106)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2180961.flac: (15, 132)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2029600.flac: (15, 85)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2143629.flac: (15, 39)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2147224.flac: (15, 58)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  19%|█▊        | 187/1000 [00:06<00:34, 23.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2443433.flac: (15, 121)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2205824.flac: (15, 82)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2143284.flac: (15, 135)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2650609.flac: (15, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  19%|█▉        | 190/1000 [00:06<00:38, 21.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2064163.flac: (15, 36)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2003555.flac: (15, 119)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2325282.flac: (15, 90)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  19%|█▉        | 194/1000 [00:06<00:36, 22.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2544279.flac: (15, 99)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2408309.flac: (15, 41)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2143139.flac: (15, 69)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2659707.flac: (15, 151)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2245044.flac: (15, 79)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2701139.flac: (15, 79)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2700160.flac: (15, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  20%|██        | 203/1000 [00:07<00:30, 25.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2157991.flac: (15, 83)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2652592.flac: (15, 167)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2190789.flac: (15, 96)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2472370.flac: (15, 171)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2649951.flac: (15, 117)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2485103.flac: (15, 69)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2635866.flac: (15, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  21%|██        | 209/1000 [00:07<00:33, 23.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2539796.flac: (15, 66)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2306198.flac: (15, 97)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2181095.flac: (15, 97)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2470548.flac: (15, 37)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2740450.flac: (15, 91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  21%|██        | 212/1000 [00:07<00:35, 22.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2292570.flac: (15, 81)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2516823.flac: (15, 53)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2316215.flac: (15, 65)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2037132.flac: (15, 63)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2544316.flac: (15, 98)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2384800.flac: (15, 89)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2642919.flac: (15, 75)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2149726.flac: (15, 107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  22%|██▏       | 221/1000 [00:08<00:31, 24.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2143984.flac: (15, 85)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2407944.flac: (15, 65)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2694362.flac: (15, 26)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2700866.flac: (15, 120)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2188109.flac: (15, 71)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  22%|██▏       | 224/1000 [00:08<00:33, 23.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2388043.flac: (15, 93)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2748619.flac: (15, 126)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2591411.flac: (15, 93)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2716900.flac: (15, 105)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  23%|██▎       | 230/1000 [00:08<00:34, 22.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2035540.flac: (15, 103)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2027730.flac: (15, 63)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2447413.flac: (15, 93)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2052461.flac: (15, 79)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2731022.flac: (15, 103)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2635702.flac: (15, 81)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  24%|██▎       | 237/1000 [00:08<00:32, 23.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2513837.flac: (15, 87)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2624239.flac: (15, 107)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2233111.flac: (15, 58)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2364713.flac: (15, 70)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2646857.flac: (15, 87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  24%|██▍       | 240/1000 [00:08<00:33, 22.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2246128.flac: (15, 110)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2109244.flac: (15, 121)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2476011.flac: (15, 79)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2443860.flac: (15, 116)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2587405.flac: (15, 85)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  25%|██▍       | 247/1000 [00:09<00:33, 22.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2456397.flac: (15, 49)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2647793.flac: (15, 120)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2199603.flac: (15, 100)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2105575.flac: (15, 127)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2578411.flac: (15, 83)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2646671.flac: (15, 75)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2324315.flac: (15, 103)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  26%|██▌       | 259/1000 [00:09<00:21, 34.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2070234.flac: (15, 106)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2143355.flac: (15, 73)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2012993.flac: (15, 91)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2664673.flac: (15, 27)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2066000.flac: (15, 94)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2584545.flac: (15, 118)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2472025.flac: (15, 125)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2732033.flac: (15, 103)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2300199.flac: (15, 128)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2623781.flac: (15, 99)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  26%|██▋       | 263/1000 [00:09<00:27, 26.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2195728.flac: (15, 52)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2053527.flac: (15, 77)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2431571.flac: (15, 123)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2085571.flac: (15, 73)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  27%|██▋       | 267/1000 [00:09<00:30, 23.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2174774.flac: (15, 64)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2217024.flac: (15, 87)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2160467.flac: (15, 104)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2408371.flac: (15, 153)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  27%|██▋       | 271/1000 [00:10<00:29, 24.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2018620.flac: (15, 97)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2404002.flac: (15, 115)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2134138.flac: (15, 45)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2547661.flac: (15, 103)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2451578.flac: (15, 77)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2393957.flac: (15, 123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  28%|██▊       | 278/1000 [00:10<00:30, 23.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2544967.flac: (15, 71)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2152962.flac: (15, 38)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2484092.flac: (15, 55)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2500597.flac: (15, 107)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2415064.flac: (15, 94)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2039765.flac: (15, 91)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  28%|██▊       | 284/1000 [00:10<00:23, 31.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2226856.flac: (15, 70)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2629646.flac: (15, 41)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2167565.flac: (15, 126)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2178879.flac: (15, 119)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2451706.flac: (15, 121)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2111885.flac: (15, 49)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2193989.flac: (15, 146)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2206826.flac: (15, 85)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  29%|██▉       | 292/1000 [00:10<00:26, 26.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2501000.flac: (15, 117)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2327117.flac: (15, 81)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2268546.flac: (15, 65)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2065424.flac: (15, 121)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2545727.flac: (15, 84)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  30%|██▉       | 295/1000 [00:11<00:29, 23.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2567638.flac: (15, 147)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2578152.flac: (15, 97)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2278330.flac: (15, 101)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2599789.flac: (15, 121)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  30%|███       | 301/1000 [00:11<00:26, 26.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2156520.flac: (15, 89)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2352879.flac: (15, 85)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2746918.flac: (15, 61)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2013561.flac: (15, 85)\n",
      "Unexpected feature shape at C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2519734.flac: (15, 97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m label \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_num\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 12\u001b[0m     feature_mf \u001b[38;5;241m=\u001b[39m feature_extraction(path)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Make sure the output is a NumPy array of fixed size\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     feature_mf \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(feature_mf)\n",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m, in \u001b[0;36mfeature_extraction\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     10\u001b[0m   \u001b[38;5;66;03m# assert isinstance(inputs, list)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m   \n\u001b[0;32m     12\u001b[0m   \u001b[38;5;66;03m# if len(inputs) == 0:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m   \u001b[38;5;66;03m# Mel-frequency cepstral coefficients\u001b[39;00m\n\u001b[0;32m     21\u001b[0m   \u001b[38;5;66;03m# https://towardsdatascience.com/learning-from-audio-the-mel-scale-mel-spectrograms-and-mel-frequency-cepstral-coefficients-f5752b6324a8\u001b[39;00m\n\u001b[0;32m     22\u001b[0m   signal, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(path, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m)  \u001b[38;5;66;03m# Load audio at 16kHz\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m   feature_mfccs \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmfcc(y\u001b[38;5;241m=\u001b[39msignal, sr\u001b[38;5;241m=\u001b[39msr, n_mfcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#   #https://librosa.org/doc/main/generated/librosa.feature.chroma_stft.html\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#   # http://labrosa.ee.columbia.edu/matlab/chroma-ansyn/\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#   stft = np.abs(librosa.stft(X))\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#   tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#   sr=sample_rate).T,axis=0)tonnetz,contrast,mel,chroma,stft\u001b[39;00m\n\u001b[0;32m     42\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m feature_mfccs\n",
      "File \u001b[1;32mc:\\Users\\yeuvi\\anaconda3\\Lib\\site-packages\\librosa\\feature\\spectral.py:1993\u001b[0m, in \u001b[0;36mmfcc\u001b[1;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, mel_norm, **kwargs)\u001b[0m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Mel-frequency cepstral coefficients (MFCCs)\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m \n\u001b[0;32m   1848\u001b[0m \u001b[38;5;124;03m.. warning:: If multi-channel audio input ``y`` is provided, the MFCC\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1989\u001b[0m \u001b[38;5;124;03m>>> fig.colorbar(img2, ax=[ax[1]])\u001b[39;00m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m S \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1992\u001b[0m     \u001b[38;5;66;03m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[39;00m\n\u001b[1;32m-> 1993\u001b[0m     S \u001b[38;5;241m=\u001b[39m power_to_db(melspectrogram(y\u001b[38;5;241m=\u001b[39my, sr\u001b[38;5;241m=\u001b[39msr, norm \u001b[38;5;241m=\u001b[39m mel_norm, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m   1995\u001b[0m fft \u001b[38;5;241m=\u001b[39m get_fftlib()\n\u001b[0;32m   1996\u001b[0m M: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m fft\u001b[38;5;241m.\u001b[39mdct(S, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mdct_type, norm\u001b[38;5;241m=\u001b[39mnorm)[\n\u001b[0;32m   1997\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :n_mfcc, :\n\u001b[0;32m   1998\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\yeuvi\\anaconda3\\Lib\\site-packages\\librosa\\core\\spectrum.py:1814\u001b[0m, in \u001b[0;36mpower_to_db\u001b[1;34m(S, ref, amin, top_db)\u001b[0m\n\u001b[0;32m   1811\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1812\u001b[0m     ref_value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(ref)\n\u001b[1;32m-> 1814\u001b[0m log_spec: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10.0\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog10(np\u001b[38;5;241m.\u001b[39mmaximum(amin, magnitude))\n\u001b[0;32m   1815\u001b[0m log_spec \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10.0\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog10(np\u001b[38;5;241m.\u001b[39mmaximum(amin, ref_value))\n\u001b[0;32m   1817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m top_db \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Sample a subset of the data\n",
    "df_subset = df_small.sample(n=1000, random_state=42)\n",
    "\n",
    "for idx, row in tqdm(df_subset.iterrows(), total=len(df_subset), desc=\"Extracting features\"):\n",
    "    path = row['audio_path']\n",
    "    label = row['label_num']\n",
    "    \n",
    "    try:\n",
    "        feature_mf = feature_extraction(path)\n",
    "\n",
    "        # Make sure the output is a NumPy array of fixed size\n",
    "        feature_mf = np.asarray(feature_mf)\n",
    "        if feature_mf.shape != (15,):  # Adjust if your MFCCs have a different size\n",
    "            print(f\"Unexpected feature shape at {path}: {feature_mf.shape}\")\n",
    "            continue\n",
    "\n",
    "        features.append(feature_mf)\n",
    "        labels.append(label)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {path}: {e}\")\n",
    "\n",
    "# Final shape checks and conversion\n",
    "if features:\n",
    "    X = np.stack(features)  # safer than np.array when shape is fixed\n",
    "    y = np.array(labels)\n",
    "    print(f\"Extracted feature shape: {X.shape}, Labels shape: {y.shape}\")\n",
    "else:\n",
    "    print(\"❌ No features extracted. Check error logs above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c622580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all audio\n",
    "file_paths = df_small ['audio_path'].tolist()\n",
    "labels = df_small ['label_num'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "672b3abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 0/2000 [00:00<?, ?it/s]C:\\Users\\yeuvi\\AppData\\Local\\Temp\\ipykernel_19616\\3737368629.py:22: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  signal, sr = librosa.load(path, sr=16000)  # Load audio at 16kHz\n",
      "Extracting features: 100%|██████████| 2000/2000 [02:18<00:00, 14.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract features for all audio files\n",
    "# X = np.array([librosa_feature_extraction(path) for path in file_paths])  # (num_samples, timesteps, features)\n",
    "# y = np.array(labels)  # (num_samples,)\n",
    "\n",
    "\n",
    "X = []\n",
    "\n",
    "for idx, row in tqdm(df_small.iterrows(), total=len(df_small), desc=\"Extracting features\"):\n",
    "#for path in file_paths:\n",
    "    feature = feature_extraction(path)  # Extract only MFCCs\n",
    "    if feature is not None and feature.shape == (15,):    # Ensure it's the correct shape\n",
    "       X.append(feature)   \n",
    "    \n",
    "\n",
    "X = np.array(X)  # (num_samples, features)\n",
    "y = np.array(labels)  # (num_samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc6d731a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted feature shape: (0,), Labels shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Extracted feature shape: {X.shape}, Labels shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da097ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "timesteps = 100  # Number of timesteps (adjust based on your feature extraction)\n",
    "features = 40    # Number of features (e.g., MFCC coefficients)\n",
    "\n",
    "# Function to extract MFCC features\n",
    "def extract_features_ai(file_path, max_pad_len=timesteps):\n",
    "    signal, sr = librosa.load(file_path, sr=16000)  # Load audio at 16kHz\n",
    "    feature_mf = librosa.feature.mfcc(signal, sr=sr, n_mfcc=features)  # Extract MFCCs\n",
    "    feature_mf = feature_mf.T  # Transpose to (timesteps, features)\n",
    "\n",
    "    # Pad or truncate to fixed length\n",
    "    if feature_mf.shape[0] < max_pad_len:\n",
    "        pad_width = max_pad_len - feature_mf.shape[0]\n",
    "        feature_mf = np.pad(feature_mf, pad_width=((0, pad_width), (0, 0)), mode='constant')\n",
    "    else:\n",
    "        feature_mf = feature_mf[:max_pad_len, :]\n",
    "\n",
    "    return feature_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a8b8f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeuvi\\AppData\\Local\\Temp\\ipykernel_7724\\3210499116.py:7: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  signal, sr = librosa.load(file_path, sr=16000)  # Load audio at 16kHz\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mfcc() takes 0 positional arguments but 1 positional argument (and 2 keyword-only arguments) were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Extract features for all audio files\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([extract_features_ai(path) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m file_paths])  \u001b[38;5;66;03m# (num_samples, timesteps, features)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(labels)\n",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m, in \u001b[0;36mextract_features_ai\u001b[1;34m(file_path, max_pad_len)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features_ai\u001b[39m(file_path, max_pad_len\u001b[38;5;241m=\u001b[39mtimesteps):\n\u001b[0;32m      7\u001b[0m     signal, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(file_path, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m)  \u001b[38;5;66;03m# Load audio at 16kHz\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     feature_mf \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmfcc(signal, sr\u001b[38;5;241m=\u001b[39msr, n_mfcc\u001b[38;5;241m=\u001b[39mfeatures)  \u001b[38;5;66;03m# Extract MFCCs\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     feature_mf \u001b[38;5;241m=\u001b[39m feature_mf\u001b[38;5;241m.\u001b[39mT  \u001b[38;5;66;03m# Transpose to (timesteps, features)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Pad or truncate to fixed length\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: mfcc() takes 0 positional arguments but 1 positional argument (and 2 keyword-only arguments) were given"
     ]
    }
   ],
   "source": [
    "# Extract features for all audio files\n",
    "X = np.array([extract_features_ai(path) for path in file_paths])  # (num_samples, timesteps, features)\n",
    "y = np.array(labels)  # (num_samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bab0e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "# Custom Data Generator\n",
    "class AudioDataGenerator(Sequence):\n",
    "    def __init__(self, file_paths, labels, batch_size=32, shuffle=True):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.file_paths))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.file_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_paths = [self.file_paths[i] for i in batch_indexes]\n",
    "        batch_labels = [self.labels[i] for i in batch_indexes]\n",
    "\n",
    "        X, y = self.__data_generation(batch_paths, batch_labels)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, batch_paths, batch_labels):\n",
    "        X = np.empty((len(batch_paths), target_len))\n",
    "        y = np.array(batch_labels)\n",
    "\n",
    "        for i, path in enumerate(batch_paths):\n",
    "            try:\n",
    "                signal, _ = librosa.load(path, sr=target_sr)\n",
    "                if len(signal) > target_len:\n",
    "                    signal = signal[:target_len]\n",
    "                else:\n",
    "                    signal = np.pad(signal, (0, target_len - len(signal)))\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {path}: {e}\")\n",
    "                signal = np.zeros(target_len)\n",
    "\n",
    "            X[i, :] = signal\n",
    "\n",
    "        return X[..., np.newaxis], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6180a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "file_paths = df_small['audio_path'].tolist()\n",
    "labels = df_small['label_num'].tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(file_paths, labels, test_size=0.2, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3707b1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators\n",
    "train_gen = AudioDataGenerator(X_train, y_train, batch_size=16)\n",
    "val_gen = AudioDataGenerator(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7341791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sr = 16000\n",
    "target_len = 2 * target_sr  # 4 seconds (64000 samples)\n",
    "\n",
    "# Model\n",
    "model2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(target_len, 1)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # binary classification\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2951175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2627366.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2082873.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2667091.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2353819.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2193989.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2452370.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2704494.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2593818.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2309182.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2517663.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2675071.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2400393.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2486180.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2081448.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2073298.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2019540.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Epoch 1/10\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2697605.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2491002.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2518494.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2158938.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2096885.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2478308.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2188109.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2537221.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2416800.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2428655.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2296625.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2160722.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2588709.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2205824.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2371128.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2327471.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2256539.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2173883.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2567638.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2645925.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2097627.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2521280.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2280628.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2222606.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2576135.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2029299.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2418312.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2215297.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2213643.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2445701.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2048618.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n",
      "Error loading C:/Users/yeuvi/Documents/MMU Doc/Degree/Y2 Sem 2/FYP2/ASVspoof2021_DF_eval/flac/DF_E_2744312.flac: Numba needs NumPy 1.24 or greater. Got NumPy 1.23.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nFailed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1, 64, 1, 32000, 16, 64] \n\t [[{{node CudnnRNN}}]]\n\t [[sequential/bidirectional/forward_lstm/PartitionedCall]] [Op:__inference_train_function_10707]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yeuvi\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\yeuvi\\anaconda3\\envs\\py310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInternalError\u001b[0m: Graph execution error:\n\nFailed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1, 64, 1, 32000, 16, 64] \n\t [[{{node CudnnRNN}}]]\n\t [[sequential/bidirectional/forward_lstm/PartitionedCall]] [Op:__inference_train_function_10707]"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history = model2.fit(train_gen, validation_data=val_gen, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd98327d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
